{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7df389",
   "metadata": {},
   "source": [
    "# Model Training (Machine Learning)\n",
    "\n",
    "We train **6 traditional ML classifiers** on nine feature-selection datasets:\n",
    "\n",
    "1. **Logistic Regression**\n",
    "2. **Gradient Boosting Classifier**\n",
    "3. **K-Nearest Neighbours**\n",
    "4. **Random Forest Classifier**\n",
    "5. **Decision Tree Classifier**\n",
    "6. **Support Vector Machine**\n",
    "\n",
    "Metrics → `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals → Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "FEATURES_BASE = Path(\"../data/processed/features\")\n",
    "PROC_BASE = Path(\"../data/processed/ml\")\n",
    "MODEL_BASE = Path(\"../models/ml\")\n",
    "FIG_BASE = Path(\"../figures/ml\")\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba050ef",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8264",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"SVM\": SVC(probability=True, random_state=RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af3e1",
   "metadata": {},
   "source": [
    "## Train All Six Models Across Nine Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ac10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ Training ML models for: {method.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    train_path = in_dir / \"train.csv\"\n",
    "    test_path = in_dir / \"test.csv\"\n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        print(f\"⚠️ Missing train/test for {method}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    train_df = train_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = test_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "    results = []\n",
    "    proc_out = PROC_BASE / method\n",
    "    model_out = MODEL_BASE / method\n",
    "    fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name, model in MODELS.items():\n",
    "        print(f\" - Training {name} ...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics = compute_metrics(y_test, y_pred)\n",
    "        metrics_row = {\"Model\": name, **metrics}\n",
    "        results.append(metrics_row)\n",
    "\n",
    "        cm_path = fig_out / f\"{name.lower().replace(' ', '_')}_confusion.png\"\n",
    "        plot_and_save_confusion(y_test, y_pred, cm_path, f\"{name} Confusion ({method.upper()})\")\n",
    "\n",
    "        model_path = model_out / f\"{name.lower().replace(' ', '_')}.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    res_df.to_csv(proc_out / \"results_traditional_ml.csv\", index=False)\n",
    "    print(f\"✅ Saved results for {method.upper()} to {proc_out / 'results_traditional_ml.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a2308",
   "metadata": {},
   "source": [
    "## Summary of Model Performance Across All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b3fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for method in METHODS:\n",
    "    res_path = PROC_BASE / method / \"results_traditional_ml.csv\"\n",
    "    if res_path.exists():\n",
    "        df = pd.read_csv(res_path)\n",
    "        df[\"Feature Set\"] = method.upper()\n",
    "        all_results.append(df)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing results for {method.upper()}\")\n",
    "\n",
    "if all_results:\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    combined_results = combined_results.sort_values([\"Feature Set\", \"Accuracy\"], ascending=[True, False])\n",
    "    \n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    display(combined_results)\n",
    "\n",
    "    summary_out = PROC_BASE / \"all_model_results_summary.csv\"\n",
    "    combined_results.to_csv(summary_out, index=False)\n",
    "    print(f\"✅ Combined model summary saved → {summary_out}\")\n",
    "else:\n",
    "    print(\"⚠️ No model results found. Please run training first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
