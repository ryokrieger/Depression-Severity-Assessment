{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5910afcb",
   "metadata": {},
   "source": [
    "# Model Training (NLP)\n",
    "\n",
    "This notebook trains 5 transformer-based NLP models:\n",
    "- BERT\n",
    "- ClinicalBERT\n",
    "- DistilBERT\n",
    "- BioBERT\n",
    "- ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d9065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    set_seed\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "NLP_FEATURE_DIR = Path(\"../data/processed/nlpfeatures\")\n",
    "PROC_OUT = Path(\"../data/processed/nlp\")\n",
    "MODEL_OUT = Path(\"../models/nlp\")\n",
    "FIG_OUT = Path(\"../figures/nlp\")\n",
    "\n",
    "for p in [PROC_OUT, MODEL_OUT, FIG_OUT]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 4\n",
    "PER_DEVICE_EVAL_BATCH_SIZE = 8\n",
    "MAX_LENGTH = 128\n",
    "LEARNING_RATE = 2e-5\n",
    "WEIGHT_DECAY = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ac5ed",
   "metadata": {},
   "source": [
    "## Load the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef03b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1617, 2)\n",
      "Test shape: (405, 2)\n",
      "\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Information</th>\n",
       "      <th>Depression Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The student is around 23-26 years old, male, s...</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The student is around 18-22 years old, male, s...</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Student Information Depression Label\n",
       "0  The student is around 23-26 years old, male, s...           Severe\n",
       "1  The student is around 18-22 years old, male, s...           Severe"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = NLP_FEATURE_DIR / \"train.csv\"\n",
    "test_csv  = NLP_FEATURE_DIR / \"test.csv\"\n",
    "\n",
    "if not train_csv.exists() or not test_csv.exists():\n",
    "    raise FileNotFoundError(f\"Train/test CSVs not found in {NLP_FEATURE_DIR}. Please run 20_feature_engineering_nlp.ipynb first.\")\n",
    "\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df  = pd.read_csv(test_csv)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"\\nSample:\")\n",
    "display(train_df.head(2))\n",
    "\n",
    "for c in [\"Student Information\", \"Depression Label\"]:\n",
    "    if c not in train_df.columns:\n",
    "        raise ValueError(f\"Column {c} missing in {train_csv}\")\n",
    "    if c not in test_df.columns:\n",
    "        raise ValueError(f\"Column {c} missing in {test_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b842b5",
   "metadata": {},
   "source": [
    "## Encode target labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd7ad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Mild', 'Minimal', 'Moderate', 'Moderately Severe', 'Severe']\n",
      "Num labels: 5\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1617\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 405\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_df[\"label_enc\"] = le.fit_transform(train_df[\"Depression Label\"].astype(str))\n",
    "test_df[\"label_enc\"]  = le.transform(test_df[\"Depression Label\"].astype(str))\n",
    "\n",
    "num_labels = len(le.classes_)\n",
    "print(\"Classes:\", list(le.classes_))\n",
    "print(\"Num labels:\", num_labels)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[[\"Student Information\", \"label_enc\"]].rename(columns={\"Student Information\":\"text\", \"label_enc\":\"label\"}))\n",
    "test_ds  = Dataset.from_pandas(test_df[[\"Student Information\", \"label_enc\"]].rename(columns={\"Student Information\":\"text\", \"label_enc\":\"label\"}))\n",
    "\n",
    "print(train_ds)\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf622a",
   "metadata": {},
   "source": [
    "## Models list and tokenizer/model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a179f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to run: ['bert-base-uncased', 'clinical-bert', 'distilbert-base-uncased', 'biobert-base-cased-v1.1', 'albert-base-v2']\n"
     ]
    }
   ],
   "source": [
    "MODELS = [\n",
    "    (\"bert-base-uncased\", \"bert-base-uncased\"),\n",
    "    (\"clinical-bert\", \"emilyalsentzer/Bio_ClinicalBERT\"),\n",
    "    (\"distilbert-base-uncased\", \"distilbert-base-uncased\"),\n",
    "    (\"biobert-base-cased-v1.1\", \"dmis-lab/biobert-base-cased-v1.1\"),\n",
    "    (\"albert-base-v2\", \"albert-base-v2\"),\n",
    "]\n",
    "\n",
    "print(\"Models to run:\", [m[0] for m in MODELS])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec66c90",
   "metadata": {},
   "source": [
    "## Define compute_metrics used by Trainer (accuracy, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33d52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(labels, preds, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\", zero_division=0)\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc220065",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c93971e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Starting training: bert-base-uncased  (HF model: bert-base-uncased)\n",
      "================================================================================\n",
      "Loading tokenizer and model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b9af812544430ca52a32c5cdd31653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1617 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96c5e060b624c1eb6940c39e979680e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryo\\AppData\\Local\\Temp\\ipykernel_15048\\2534601247.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2025' max='2025' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2025/2025 2:11:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.505500</td>\n",
       "      <td>1.401034</td>\n",
       "      <td>0.353086</td>\n",
       "      <td>0.361742</td>\n",
       "      <td>0.353086</td>\n",
       "      <td>0.335781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.365800</td>\n",
       "      <td>1.376419</td>\n",
       "      <td>0.385185</td>\n",
       "      <td>0.387206</td>\n",
       "      <td>0.385185</td>\n",
       "      <td>0.373754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.338200</td>\n",
       "      <td>1.355119</td>\n",
       "      <td>0.402469</td>\n",
       "      <td>0.402162</td>\n",
       "      <td>0.402469</td>\n",
       "      <td>0.394751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.309400</td>\n",
       "      <td>1.331164</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.441004</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.409686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.285800</td>\n",
       "      <td>1.341254</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.440107</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.413036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ..\\models\\nlp\\bert-base-uncased\n",
      "Running final evaluation on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final metrics: {'eval_loss': 1.3412543535232544, 'eval_accuracy': 0.42962962962962964, 'eval_precision': 0.44010671590503525, 'eval_recall': 0.42962962962962964, 'eval_f1': 0.4130359652484164, 'eval_runtime': 69.9825, 'eval_samples_per_second': 5.787, 'eval_steps_per_second': 0.729, 'epoch': 5.0}\n",
      "Saved epoch metrics CSV -> ..\\data\\processed\\nlp\\bert-base-uncased_results.csv\n",
      "Saved final metrics -> ..\\data\\processed\\nlp\\bert-base-uncased_final_metrics.csv\n",
      "Saved accuracy vs epoch -> ..\\figures\\nlp\\bert-base-uncased\\bert-base-uncased_accuracy_epoch.png\n",
      "Computing confusion matrix on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix -> ..\\figures\\nlp\\bert-base-uncased\\bert-base-uncased_confusion.png\n",
      "Saved label mapping -> ..\\models\\nlp\\bert-base-uncased\\label_mapping.csv\n",
      "Finished model: bert-base-uncased\n",
      "\n",
      "================================================================================\n",
      "Starting training: clinical-bert  (HF model: emilyalsentzer/Bio_ClinicalBERT)\n",
      "================================================================================\n",
      "Loading tokenizer and model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e965cbac634364a0ce986ee2a38c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ryo\\.cache\\huggingface\\hub\\models--emilyalsentzer--Bio_ClinicalBERT. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c885f3e59a804ec39012303bf342896f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363367aa2e314321ba1d454ea6a7e68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b27a83fd0d44101b0d9c699205a5dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1617 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0909d2ad234d259e4e7e12ae4ee8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryo\\AppData\\Local\\Temp\\ipykernel_15048\\2534601247.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8967fdafee0f46af9f57ee42fe0ae109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2025' max='2025' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2025/2025 1:40:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.459600</td>\n",
       "      <td>1.389343</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.298126</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.299724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.356900</td>\n",
       "      <td>1.360300</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.381969</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.355665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.341800</td>\n",
       "      <td>1.372990</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.403772</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.383995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.325500</td>\n",
       "      <td>1.337729</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.424873</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.404745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.298400</td>\n",
       "      <td>1.346020</td>\n",
       "      <td>0.434568</td>\n",
       "      <td>0.433070</td>\n",
       "      <td>0.434568</td>\n",
       "      <td>0.408489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ..\\models\\nlp\\clinical-bert\n",
      "Running final evaluation on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final metrics: {'eval_loss': 1.3460198640823364, 'eval_accuracy': 0.4345679012345679, 'eval_precision': 0.43306970657332516, 'eval_recall': 0.4345679012345679, 'eval_f1': 0.4084890940747257, 'eval_runtime': 68.9985, 'eval_samples_per_second': 5.87, 'eval_steps_per_second': 0.739, 'epoch': 5.0}\n",
      "Saved epoch metrics CSV -> ..\\data\\processed\\nlp\\clinical-bert_results.csv\n",
      "Saved final metrics -> ..\\data\\processed\\nlp\\clinical-bert_final_metrics.csv\n",
      "Saved accuracy vs epoch -> ..\\figures\\nlp\\clinical-bert\\clinical-bert_accuracy_epoch.png\n",
      "Computing confusion matrix on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix -> ..\\figures\\nlp\\clinical-bert\\clinical-bert_confusion.png\n",
      "Saved label mapping -> ..\\models\\nlp\\clinical-bert\\label_mapping.csv\n",
      "Finished model: clinical-bert\n",
      "\n",
      "================================================================================\n",
      "Starting training: distilbert-base-uncased  (HF model: distilbert-base-uncased)\n",
      "================================================================================\n",
      "Loading tokenizer and model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a001b118d9e44dc888a7308233b3928b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ryo\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fee63e9a22413793d3a8f0d5312e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b926216f88458da3fb162145ef4183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978baf0bba184e0781abd43b3237772d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49c82dc0ac6416d96f926bab597bb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc907f6587114ae1ab018b8010d42d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1617 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2087d1d703d44cd083107bce12e2ce0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryo\\AppData\\Local\\Temp\\ipykernel_15048\\2534601247.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2025' max='2025' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2025/2025 42:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.454200</td>\n",
       "      <td>1.370242</td>\n",
       "      <td>0.385185</td>\n",
       "      <td>0.320146</td>\n",
       "      <td>0.385185</td>\n",
       "      <td>0.323910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.349000</td>\n",
       "      <td>1.362444</td>\n",
       "      <td>0.414815</td>\n",
       "      <td>0.413961</td>\n",
       "      <td>0.414815</td>\n",
       "      <td>0.384131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.325700</td>\n",
       "      <td>1.355455</td>\n",
       "      <td>0.414815</td>\n",
       "      <td>0.424598</td>\n",
       "      <td>0.414815</td>\n",
       "      <td>0.401226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.305400</td>\n",
       "      <td>1.338718</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.398010</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.384095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.293500</td>\n",
       "      <td>1.345803</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.435941</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.409886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ..\\models\\nlp\\distilbert-base-uncased\n",
      "Running final evaluation on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final metrics: {'eval_loss': 1.3458025455474854, 'eval_accuracy': 0.43209876543209874, 'eval_precision': 0.43594121228326266, 'eval_recall': 0.43209876543209874, 'eval_f1': 0.4098860543050653, 'eval_runtime': 28.2442, 'eval_samples_per_second': 14.339, 'eval_steps_per_second': 1.806, 'epoch': 5.0}\n",
      "Saved epoch metrics CSV -> ..\\data\\processed\\nlp\\distilbert-base-uncased_results.csv\n",
      "Saved final metrics -> ..\\data\\processed\\nlp\\distilbert-base-uncased_final_metrics.csv\n",
      "Saved accuracy vs epoch -> ..\\figures\\nlp\\distilbert-base-uncased\\distilbert-base-uncased_accuracy_epoch.png\n",
      "Computing confusion matrix on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix -> ..\\figures\\nlp\\distilbert-base-uncased\\distilbert-base-uncased_confusion.png\n",
      "Saved label mapping -> ..\\models\\nlp\\distilbert-base-uncased\\label_mapping.csv\n",
      "Finished model: distilbert-base-uncased\n",
      "\n",
      "================================================================================\n",
      "Starting training: biobert-base-cased-v1.1  (HF model: dmis-lab/biobert-base-cased-v1.1)\n",
      "================================================================================\n",
      "Loading tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: af0b25c3-fa78-49b5-997e-27ec899edbb4)')' thrown while requesting HEAD https://huggingface.co/dmis-lab/biobert-base-cased-v1.1/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0873f3f98024ca588e2291607b31b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ryo\\.cache\\huggingface\\hub\\models--dmis-lab--biobert-base-cased-v1.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3864f2c0e66e4eebb5daab1341f36993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b2c197eca54184af778faa0169a610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b46d3c510a4b548f1ca6f9467b9a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1617 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd4f97c32434385a594b82059a4ab03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryo\\AppData\\Local\\Temp\\ipykernel_15048\\2534601247.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2025' max='2025' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2025/2025 1:21:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.487600</td>\n",
       "      <td>1.385243</td>\n",
       "      <td>0.380247</td>\n",
       "      <td>0.375241</td>\n",
       "      <td>0.380247</td>\n",
       "      <td>0.353156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.362500</td>\n",
       "      <td>1.363272</td>\n",
       "      <td>0.387654</td>\n",
       "      <td>0.368123</td>\n",
       "      <td>0.387654</td>\n",
       "      <td>0.350720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.331400</td>\n",
       "      <td>1.364048</td>\n",
       "      <td>0.392593</td>\n",
       "      <td>0.392175</td>\n",
       "      <td>0.392593</td>\n",
       "      <td>0.385011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.296000</td>\n",
       "      <td>1.334336</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.394589</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.375789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.269300</td>\n",
       "      <td>1.352443</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.413351</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.393020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb7c237f935491fa48b87fef3f9ac78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ..\\models\\nlp\\biobert-base-cased-v1.1\n",
      "Running final evaluation on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final metrics: {'eval_loss': 1.3524428606033325, 'eval_accuracy': 0.4074074074074074, 'eval_precision': 0.41335055724166936, 'eval_recall': 0.4074074074074074, 'eval_f1': 0.39302031034179946, 'eval_runtime': 56.4091, 'eval_samples_per_second': 7.18, 'eval_steps_per_second': 0.904, 'epoch': 5.0}\n",
      "Saved epoch metrics CSV -> ..\\data\\processed\\nlp\\biobert-base-cased-v1.1_results.csv\n",
      "Saved final metrics -> ..\\data\\processed\\nlp\\biobert-base-cased-v1.1_final_metrics.csv\n",
      "Saved accuracy vs epoch -> ..\\figures\\nlp\\biobert-base-cased-v1.1\\biobert-base-cased-v1.1_accuracy_epoch.png\n",
      "Computing confusion matrix on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix -> ..\\figures\\nlp\\biobert-base-cased-v1.1\\biobert-base-cased-v1.1_confusion.png\n",
      "Saved label mapping -> ..\\models\\nlp\\biobert-base-cased-v1.1\\label_mapping.csv\n",
      "Finished model: biobert-base-cased-v1.1\n",
      "\n",
      "================================================================================\n",
      "Starting training: albert-base-v2  (HF model: albert-base-v2)\n",
      "================================================================================\n",
      "Loading tokenizer and model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75ff7bb17c54544a99d5cdaa042705f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ryo\\.cache\\huggingface\\hub\\models--albert-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff61a11636be413194fe367bd61a0764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa87d833ecfb448089bf70eb52f81cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b25afa8a62d4bb1a0bebe732f5d76cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202f4f6731a444b2aa084017d5228748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1183380ba644afaa7716e35c53a74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1617 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eea2814f25c4379a3a7c45167786ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryo\\AppData\\Local\\Temp\\ipykernel_15048\\2534601247.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2025' max='2025' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2025/2025 1:09:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.556300</td>\n",
       "      <td>1.482322</td>\n",
       "      <td>0.353086</td>\n",
       "      <td>0.226284</td>\n",
       "      <td>0.353086</td>\n",
       "      <td>0.253817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.432400</td>\n",
       "      <td>1.424890</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.253925</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.399400</td>\n",
       "      <td>1.426102</td>\n",
       "      <td>0.350617</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.350617</td>\n",
       "      <td>0.288883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.370900</td>\n",
       "      <td>1.361054</td>\n",
       "      <td>0.367901</td>\n",
       "      <td>0.425815</td>\n",
       "      <td>0.367901</td>\n",
       "      <td>0.374889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.323900</td>\n",
       "      <td>1.354619</td>\n",
       "      <td>0.412346</td>\n",
       "      <td>0.412118</td>\n",
       "      <td>0.412346</td>\n",
       "      <td>0.393086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ..\\models\\nlp\\albert-base-v2\n",
      "Running final evaluation on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final metrics: {'eval_loss': 1.354619026184082, 'eval_accuracy': 0.4123456790123457, 'eval_precision': 0.412117884578736, 'eval_recall': 0.4123456790123457, 'eval_f1': 0.3930856324660449, 'eval_runtime': 61.062, 'eval_samples_per_second': 6.633, 'eval_steps_per_second': 0.835, 'epoch': 5.0}\n",
      "Saved epoch metrics CSV -> ..\\data\\processed\\nlp\\albert-base-v2_results.csv\n",
      "Saved final metrics -> ..\\data\\processed\\nlp\\albert-base-v2_final_metrics.csv\n",
      "Saved accuracy vs epoch -> ..\\figures\\nlp\\albert-base-v2\\albert-base-v2_accuracy_epoch.png\n",
      "Computing confusion matrix on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\CSE299\\Depression Assessment\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix -> ..\\figures\\nlp\\albert-base-v2\\albert-base-v2_confusion.png\n",
      "Saved label mapping -> ..\\models\\nlp\\albert-base-v2\\label_mapping.csv\n",
      "Finished model: albert-base-v2\n"
     ]
    }
   ],
   "source": [
    "RUN_MODELS = MODELS\n",
    "\n",
    "from transformers import logging as tf_logging\n",
    "tf_logging.set_verbosity_error()\n",
    "\n",
    "for slug, hf_name in RUN_MODELS:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Starting training: {slug}  (HF model: {hf_name})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_out_dir = MODEL_OUT / slug\n",
    "    fig_out_dir = FIG_OUT / slug\n",
    "    proc_out_dir = PROC_OUT\n",
    "    model_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    proc_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"Loading tokenizer and model...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(hf_name, use_fast=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(hf_name, num_labels=num_labels)\n",
    "\n",
    "    def tokenize_fn(batch):\n",
    "        return tokenizer(batch[\"text\"], truncation=True, padding=False, max_length=MAX_LENGTH)\n",
    "\n",
    "    tokenized_train = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "    tokenized_test  = test_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(model_out_dir),\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "        per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        disable_tqdm=False,\n",
    "        load_best_model_at_end=False,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        fp16=False,\n",
    "        push_to_hub=False\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_test,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    print(\"Beginning training...\")\n",
    "    train_result = trainer.train()\n",
    "    trainer.save_model(str(model_out_dir))\n",
    "    print(\"Model saved to:\", model_out_dir)\n",
    "\n",
    "    print(\"Running final evaluation on test set...\")\n",
    "    metrics = trainer.evaluate(eval_dataset=tokenized_test)\n",
    "    print(\"Final metrics:\", metrics)\n",
    "\n",
    "    logs = trainer.state.log_history\n",
    "    epoch_nums = []\n",
    "    epoch_acc = []\n",
    "    epoch_prec = []\n",
    "    epoch_rec = []\n",
    "    epoch_f1 = []\n",
    "    for entry in logs:\n",
    "        if \"eval_accuracy\" in entry:\n",
    "            epoch_nums.append(entry.get(\"epoch\"))\n",
    "            epoch_acc.append(entry.get(\"eval_accuracy\"))\n",
    "            epoch_prec.append(entry.get(\"eval_precision\"))\n",
    "            epoch_rec.append(entry.get(\"eval_recall\"))\n",
    "            epoch_f1.append(entry.get(\"eval_f1\"))\n",
    "    if not epoch_nums:\n",
    "        epoch_nums = [i+1 for i in range(NUM_EPOCHS)]\n",
    "        epoch_acc = [metrics.get(\"eval_accuracy\")] * NUM_EPOCHS\n",
    "        epoch_prec = [metrics.get(\"eval_precision\")] * NUM_EPOCHS\n",
    "        epoch_rec = [metrics.get(\"eval_recall\")] * NUM_EPOCHS\n",
    "        epoch_f1 = [metrics.get(\"eval_f1\")] * NUM_EPOCHS\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        \"epoch\": epoch_nums,\n",
    "        \"accuracy\": epoch_acc,\n",
    "        \"precision\": epoch_prec,\n",
    "        \"recall\": epoch_rec,\n",
    "        \"f1\": epoch_f1\n",
    "    })\n",
    "    results_csv = proc_out_dir / f\"{slug}_results.csv\"\n",
    "    results_df.to_csv(results_csv, index=False)\n",
    "    print(\"Saved epoch metrics CSV ->\", results_csv)\n",
    "    \n",
    "    summary_out = proc_out_dir / f\"{slug}_final_metrics.csv\"\n",
    "    pd.DataFrame([metrics]).to_csv(summary_out, index=False)\n",
    "    print(\"Saved final metrics ->\", summary_out)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.plot(epoch_nums, epoch_acc, marker='o', label='Accuracy')\n",
    "    ax.plot(epoch_nums, epoch_f1, marker='o', label='F1')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(f\"{slug}  Accuracy/F1 vs Epoch\")\n",
    "    ax.set_xticks(epoch_nums)\n",
    "    ax.legend()\n",
    "    acc_fig_path = fig_out_dir / f\"{slug}_accuracy_epoch.png\"\n",
    "    fig.savefig(acc_fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"Saved accuracy vs epoch ->\", acc_fig_path)\n",
    "\n",
    "    print(\"Computing confusion matrix on test set...\")\n",
    "    preds_output = trainer.predict(tokenized_test)\n",
    "    pred_labels = np.argmax(preds_output.predictions, axis=-1)\n",
    "    true_labels = preds_output.label_ids\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    cm_fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(f\"{slug}  Confusion Matrix\")\n",
    "    cm_path = fig_out_dir / f\"{slug}_confusion.png\"\n",
    "    cm_fig.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(cm_fig)\n",
    "    print(\"Saved confusion matrix ->\", cm_path)\n",
    "\n",
    "    mapping_path = model_out_dir / \"label_mapping.csv\"\n",
    "    pd.DataFrame({\"label\": list(le.classes_), \"enc\": list(range(len(le.classes_)))}).to_csv(mapping_path, index=False)\n",
    "    print(\"Saved label mapping ->\", mapping_path)\n",
    "    \n",
    "    print(f\"Finished model: {slug}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c885b",
   "metadata": {},
   "source": [
    "## Aggregate per-model final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd34900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.440107</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.413036</td>\n",
       "      <td>1.341254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical-bert</td>\n",
       "      <td>0.434568</td>\n",
       "      <td>0.433070</td>\n",
       "      <td>0.434568</td>\n",
       "      <td>0.408489</td>\n",
       "      <td>1.346020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.435941</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.409886</td>\n",
       "      <td>1.345803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biobert-base-cased-v1.1</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.413351</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.393020</td>\n",
       "      <td>1.352443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>0.412346</td>\n",
       "      <td>0.412118</td>\n",
       "      <td>0.412346</td>\n",
       "      <td>0.393086</td>\n",
       "      <td>1.354619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  eval_accuracy  eval_precision  eval_recall  \\\n",
       "0        bert-base-uncased       0.429630        0.440107     0.429630   \n",
       "1            clinical-bert       0.434568        0.433070     0.434568   \n",
       "2  distilbert-base-uncased       0.432099        0.435941     0.432099   \n",
       "3  biobert-base-cased-v1.1       0.407407        0.413351     0.407407   \n",
       "4           albert-base-v2       0.412346        0.412118     0.412346   \n",
       "\n",
       "    eval_f1  eval_loss  \n",
       "0  0.413036   1.341254  \n",
       "1  0.408489   1.346020  \n",
       "2  0.409886   1.345803  \n",
       "3  0.393020   1.352443  \n",
       "4  0.393086   1.354619  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined summary -> ..\\data\\processed\\nlp\\all_nlp_models_summary.csv\n"
     ]
    }
   ],
   "source": [
    "agg = []\n",
    "for slug, hf_name in MODELS:\n",
    "    summary_out = PROC_OUT / f\"{slug}_final_metrics.csv\"\n",
    "    if summary_out.exists():\n",
    "        dfm = pd.read_csv(summary_out)\n",
    "        dfm[\"model\"] = slug\n",
    "        agg.append(dfm)\n",
    "    else:\n",
    "        print(\"Summary missing for\", slug)\n",
    "\n",
    "if agg:\n",
    "    combined = pd.concat(agg, ignore_index=True, sort=False)\n",
    "    display(combined[[\"model\", \"eval_accuracy\", \"eval_precision\", \"eval_recall\", \"eval_f1\", \"eval_loss\"]])\n",
    "    combined.to_csv(PROC_OUT / \"all_nlp_models_summary.csv\", index=False)\n",
    "    print(\"Saved combined summary ->\", PROC_OUT / \"all_nlp_models_summary.csv\")\n",
    "else:\n",
    "    print(\"No final metrics found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
