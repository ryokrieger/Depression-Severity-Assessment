{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7df389",
   "metadata": {},
   "source": [
    "# Model Training (Machine Learning)\n",
    "\n",
    "We train **6 traditional ML classifiers** on nine feature-selection datasets:\n",
    "\n",
    "1. **Logistic Regression**\n",
    "2. **Gradient Boosting Classifier**\n",
    "3. **K-Nearest Neighbours**\n",
    "4. **Random Forest Classifier**\n",
    "5. **Decision Tree Classifier**\n",
    "6. **Support Vector Machine**\n",
    "\n",
    "Metrics → `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals → Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c1edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "FEATURES_BASE = Path(\"../data/processed/features3\")\n",
    "PROC_BASE = Path(\"../data/processed/ml3\")\n",
    "MODEL_BASE = Path(\"../models/ml3\")\n",
    "FIG_BASE = Path(\"../figures/ml3\")\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba050ef",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }\n",
    "\n",
    "def save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(title)\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8264",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"SVM\": SVC(probability=True, random_state=RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af3e1",
   "metadata": {},
   "source": [
    "## Train All Six Models Across Nine Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0ac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: RFE\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\rfe\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: SKB\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\skb\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: FSCS\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\fscs\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: ETC\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\etc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: PC\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\pc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: MI\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\mi\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: MIR\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\mir\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: MU\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\mu\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: VT\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\vt\\results_traditional_ml.csv\n"
     ]
    }
   ],
   "source": [
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ Training ML models for feature set: {method.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    train_path = in_dir / \"train.csv\"\n",
    "    test_path = in_dir / \"test.csv\"\n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        print(f\"⚠️ Missing train/test for {method}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    train_df = pd.read_csv(train_path).dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = pd.read_csv(test_path).dropna(subset=[\"DepressionEncoded\"])\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "    results = []\n",
    "    proc_out = PROC_BASE / method; model_out = MODEL_BASE / method; fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name, model in MODELS.items():\n",
    "        print(f\" - Training: {name}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics = compute_metrics(y_test, y_pred)\n",
    "        results.append({\"Model\": name, **metrics})\n",
    "\n",
    "        save_confusion(y_test, y_pred, fig_out / f\"{name.lower().replace(' ', '_')}_confusion.png\", f\"{name} Confusion ({method.upper()})\")\n",
    "        joblib.dump(model, model_out / f\"{name.lower().replace(' ', '_')}.pkl\")\n",
    "\n",
    "    pd.DataFrame(results).to_csv(proc_out / \"results_traditional_ml.csv\", index=False)\n",
    "    print(f\"✅ Saved metrics to: {proc_out / 'results_traditional_ml.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a2308",
   "metadata": {},
   "source": [
    "## Summary of Model Performance Across All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207b3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.841975</td>\n",
       "      <td>0.840729</td>\n",
       "      <td>0.841975</td>\n",
       "      <td>0.840932</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.816826</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.816256</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.802237</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800764</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.782126</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.780741</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.753689</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.752914</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.688631</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.688024</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>0.824630</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>0.819047</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.814889</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.811871</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.793769</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789639</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.783462</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.779191</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.747872</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.745534</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.686868</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.684342</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.818673</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817431</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797769</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797172</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.795583</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.793802</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.773462</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.772620</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730383</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730931</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>0.674431</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>0.672212</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.841975</td>\n",
       "      <td>0.845012</td>\n",
       "      <td>0.841975</td>\n",
       "      <td>0.842110</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.827917</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.825527</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.818332</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817416</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.805631</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.805170</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.765948</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.766151</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.720945</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.719495</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.807343</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.805639</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797610</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.796015</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.791067</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.786485</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.737824</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.738478</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.714516</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.714380</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.818673</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817431</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797769</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797172</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.795583</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.793802</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.762982</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.762151</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730383</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730931</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>0.674431</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>0.672212</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.829630</td>\n",
       "      <td>0.830397</td>\n",
       "      <td>0.829630</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797824</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.796585</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.780714</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.778873</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.776490</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.775412</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.751718</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.752047</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.713580</td>\n",
       "      <td>0.711888</td>\n",
       "      <td>0.713580</td>\n",
       "      <td>0.712020</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.818673</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817431</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797769</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797172</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.795583</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.793802</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.768500</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.767791</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730383</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.730931</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.671605</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.671605</td>\n",
       "      <td>0.669352</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.849383</td>\n",
       "      <td>0.851775</td>\n",
       "      <td>0.849383</td>\n",
       "      <td>0.849704</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.810687</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.808316</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.810695</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.806991</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.788387</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.783915</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.744992</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.742296</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.717040</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.711425</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall        F1 Feature Set\n",
       "18  Logistic Regression  0.841975   0.840729  0.841975  0.840932         ETC\n",
       "23                  SVM  0.817284   0.816826  0.817284  0.816256         ETC\n",
       "21        Random Forest  0.800000   0.802237  0.800000  0.800764         ETC\n",
       "19    Gradient Boosting  0.780247   0.782126  0.780247  0.780741         ETC\n",
       "20                  KNN  0.753086   0.753689  0.753086  0.752914         ETC\n",
       "22        Decision Tree  0.688889   0.688631  0.688889  0.688024         ETC\n",
       "12  Logistic Regression  0.819753   0.824630  0.819753  0.819047        FSCS\n",
       "17                  SVM  0.812346   0.814889  0.812346  0.811871        FSCS\n",
       "13    Gradient Boosting  0.790123   0.793769  0.790123  0.789639        FSCS\n",
       "15        Random Forest  0.780247   0.783462  0.780247  0.779191        FSCS\n",
       "14                  KNN  0.745679   0.747872  0.745679  0.745534        FSCS\n",
       "16        Decision Tree  0.688889   0.686868  0.688889  0.684342        FSCS\n",
       "30  Logistic Regression  0.817284   0.818673  0.817284  0.817431          MI\n",
       "31    Gradient Boosting  0.797531   0.797769  0.797531  0.797172          MI\n",
       "35                  SVM  0.795062   0.795583  0.795062  0.793802          MI\n",
       "33        Random Forest  0.772840   0.773462  0.772840  0.772620          MI\n",
       "32                  KNN  0.733333   0.730383  0.733333  0.730931          MI\n",
       "34        Decision Tree  0.674074   0.674431  0.674074  0.672212          MI\n",
       "36  Logistic Regression  0.841975   0.845012  0.841975  0.842110         MIR\n",
       "41                  SVM  0.824691   0.827917  0.824691  0.825527         MIR\n",
       "37    Gradient Boosting  0.817284   0.818332  0.817284  0.817416         MIR\n",
       "39        Random Forest  0.804938   0.805631  0.804938  0.805170         MIR\n",
       "38                  KNN  0.767901   0.765948  0.767901  0.766151         MIR\n",
       "40        Decision Tree  0.718519   0.720945  0.718519  0.719495         MIR\n",
       "43    Gradient Boosting  0.804938   0.807343  0.804938  0.805639          MU\n",
       "42  Logistic Regression  0.797531   0.798942  0.797531  0.797610          MU\n",
       "47                  SVM  0.792593   0.796015  0.792593  0.793558          MU\n",
       "45        Random Forest  0.785185   0.791067  0.785185  0.786485          MU\n",
       "44                  KNN  0.740741   0.737824  0.740741  0.738478          MU\n",
       "46        Decision Tree  0.716049   0.714516  0.716049  0.714380          MU\n",
       "24  Logistic Regression  0.817284   0.818673  0.817284  0.817431          PC\n",
       "25    Gradient Boosting  0.797531   0.797769  0.797531  0.797172          PC\n",
       "29                  SVM  0.795062   0.795583  0.795062  0.793802          PC\n",
       "27        Random Forest  0.762963   0.762982  0.762963  0.762151          PC\n",
       "26                  KNN  0.733333   0.730383  0.733333  0.730931          PC\n",
       "28        Decision Tree  0.674074   0.674431  0.674074  0.672212          PC\n",
       "0   Logistic Regression  0.829630   0.830397  0.829630  0.829563         RFE\n",
       "5                   SVM  0.797531   0.797824  0.797531  0.796585         RFE\n",
       "3         Random Forest  0.777778   0.780714  0.777778  0.778873         RFE\n",
       "1     Gradient Boosting  0.775309   0.776490  0.775309  0.775412         RFE\n",
       "2                   KNN  0.753086   0.751718  0.753086  0.752047         RFE\n",
       "4         Decision Tree  0.713580   0.711888  0.713580  0.712020         RFE\n",
       "6   Logistic Regression  0.817284   0.818673  0.817284  0.817431         SKB\n",
       "7     Gradient Boosting  0.797531   0.797769  0.797531  0.797172         SKB\n",
       "11                  SVM  0.795062   0.795583  0.795062  0.793802         SKB\n",
       "9         Random Forest  0.767901   0.768500  0.767901  0.767791         SKB\n",
       "8                   KNN  0.733333   0.730383  0.733333  0.730931         SKB\n",
       "10        Decision Tree  0.671605   0.671533  0.671605  0.669352         SKB\n",
       "48  Logistic Regression  0.849383   0.851775  0.849383  0.849704          VT\n",
       "49    Gradient Boosting  0.807407   0.810687  0.807407  0.808316          VT\n",
       "53                  SVM  0.807407   0.810695  0.807407  0.806991          VT\n",
       "51        Random Forest  0.782716   0.788387  0.782716  0.783915          VT\n",
       "50                  KNN  0.740741   0.744992  0.740741  0.742296          VT\n",
       "52        Decision Tree  0.711111   0.717040  0.711111  0.711425          VT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined model summary saved → ..\\data\\processed\\ml3\\all_model_results_summary_v4.csv\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for method in METHODS:\n",
    "    res_path = PROC_BASE / method / \"results_traditional_ml.csv\"\n",
    "    if res_path.exists():\n",
    "        df = pd.read_csv(res_path)\n",
    "        df[\"Feature Set\"] = method.upper()\n",
    "        all_results.append(df)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing results for {method.upper()}\")\n",
    "\n",
    "if all_results:\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    combined_results = combined_results.sort_values([\"Feature Set\", \"Accuracy\"], ascending=[True, False])\n",
    "\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    display(combined_results)\n",
    "    \n",
    "    summary_out = PROC_BASE / \"all_model_results_summary_v4.csv\"\n",
    "    combined_results.to_csv(summary_out, index=False)\n",
    "    print(f\"✅ Combined model summary saved → {summary_out}\")\n",
    "else:\n",
    "    print(\"⚠️ No model results found. Please run training first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
