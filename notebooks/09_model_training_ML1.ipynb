{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7df389",
   "metadata": {},
   "source": [
    "# Model Training (Machine Learning)\n",
    "\n",
    "We train **6 traditional ML classifiers** on nine feature-selection datasets:\n",
    "\n",
    "1. **Logistic Regression**\n",
    "2. **Gradient Boosting Classifier**\n",
    "3. **K-Nearest Neighbours**\n",
    "4. **Random Forest Classifier**\n",
    "5. **Decision Tree Classifier**\n",
    "6. **Support Vector Machine**\n",
    "\n",
    "Metrics → `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals → Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c1edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "FEATURES_BASE = Path(\"../data/processed/features1\")\n",
    "PROC_BASE = Path(\"../data/processed/ml1\")\n",
    "MODEL_BASE = Path(\"../models/ml1\")\n",
    "FIG_BASE = Path(\"../figures/ml1\")\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba050ef",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8264",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"SVM\": SVC(probability=True, random_state=RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af3e1",
   "metadata": {},
   "source": [
    "## Train All Six Models Across Nine Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0ac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Training ML models for: RFE\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for RFE to ..\\data\\processed\\ml1\\rfe\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: SKB\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for SKB to ..\\data\\processed\\ml1\\skb\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: FSCS\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for FSCS to ..\\data\\processed\\ml1\\fscs\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: ETC\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for ETC to ..\\data\\processed\\ml1\\etc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: PC\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for PC to ..\\data\\processed\\ml1\\pc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MI\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MI to ..\\data\\processed\\ml1\\mi\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MIR\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MIR to ..\\data\\processed\\ml1\\mir\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MU\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MU to ..\\data\\processed\\ml1\\mu\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: VT\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for VT to ..\\data\\processed\\ml1\\vt\\results_traditional_ml.csv\n"
     ]
    }
   ],
   "source": [
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ Training ML models for: {method.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    train_path = in_dir / \"train.csv\"\n",
    "    test_path = in_dir / \"test.csv\"\n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        print(f\"⚠️ Missing train/test for {method}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    train_df = train_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = test_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "    results = []\n",
    "    proc_out = PROC_BASE / method\n",
    "    model_out = MODEL_BASE / method\n",
    "    fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name, model in MODELS.items():\n",
    "        print(f\" - Training {name} ...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics = compute_metrics(y_test, y_pred)\n",
    "        metrics_row = {\"Model\": name, **metrics}\n",
    "        results.append(metrics_row)\n",
    "\n",
    "        cm_path = fig_out / f\"{name.lower().replace(' ', '_')}_confusion.png\"\n",
    "        plot_and_save_confusion(y_test, y_pred, cm_path, f\"{name} Confusion ({method.upper()})\")\n",
    "\n",
    "        model_path = model_out / f\"{name.lower().replace(' ', '_')}.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    res_df.to_csv(proc_out / \"results_traditional_ml.csv\", index=False)\n",
    "    print(f\"✅ Saved results for {method.upper()} to {proc_out / 'results_traditional_ml.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a2308",
   "metadata": {},
   "source": [
    "## Summary of Model Performance Across All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207b3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.836223</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.835266</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817255</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.816939</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.783921</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.780265</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.778559</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.720712</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.715652</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>0.693970</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>0.694147</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.815919</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.812285</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.812084</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.808148</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.804078</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797543</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.771343</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.767184</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.729093</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.714802</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.708642</td>\n",
       "      <td>0.705515</td>\n",
       "      <td>0.708642</td>\n",
       "      <td>0.705657</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.818823</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817552</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.816174</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.814977</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.774527</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.772246</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.772990</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.770124</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.736358</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.726129</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.664198</td>\n",
       "      <td>0.660441</td>\n",
       "      <td>0.664198</td>\n",
       "      <td>0.661185</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.842813</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.839901</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>0.822455</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>0.819837</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.790346</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789713</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.786896</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.785659</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.708642</td>\n",
       "      <td>0.711831</td>\n",
       "      <td>0.708642</td>\n",
       "      <td>0.705962</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.671605</td>\n",
       "      <td>0.669497</td>\n",
       "      <td>0.671605</td>\n",
       "      <td>0.670138</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801515</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799689</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.790187</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.787359</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.782644</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.782141</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.763907</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.758346</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.683951</td>\n",
       "      <td>0.682719</td>\n",
       "      <td>0.683951</td>\n",
       "      <td>0.683274</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.664198</td>\n",
       "      <td>0.666898</td>\n",
       "      <td>0.664198</td>\n",
       "      <td>0.663362</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.825921</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.824633</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817684</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.816995</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.785805</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.782173</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.763578</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.761818</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>0.714955</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>0.694517</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.659259</td>\n",
       "      <td>0.658831</td>\n",
       "      <td>0.659259</td>\n",
       "      <td>0.658298</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.819584</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817786</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.815649</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.815028</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.795209</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.793446</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.790931</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.787384</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.708551</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.663335</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.664280</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.818823</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817552</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.816174</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.814977</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.781573</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.780244</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.774527</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.772246</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.736358</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.726129</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.676543</td>\n",
       "      <td>0.675238</td>\n",
       "      <td>0.676543</td>\n",
       "      <td>0.675615</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.831195</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.827344</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.805783</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.802461</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.783048</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.780933</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.769560</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.765347</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.736353</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.728945</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.671372</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.664488</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall        F1 Feature Set\n",
       "18  Logistic Regression  0.837037   0.836223  0.837037  0.835266         ETC\n",
       "23                  SVM  0.817284   0.817255  0.817284  0.816939         ETC\n",
       "19    Gradient Boosting  0.782716   0.783921  0.782716  0.783217         ETC\n",
       "21        Random Forest  0.777778   0.780265  0.777778  0.778559         ETC\n",
       "20                  KNN  0.718519   0.720712  0.718519  0.715652         ETC\n",
       "22        Decision Tree  0.698765   0.693970  0.698765  0.694147         ETC\n",
       "12  Logistic Regression  0.812346   0.815919  0.812346  0.812285        FSCS\n",
       "17                  SVM  0.807407   0.812084  0.807407  0.808148        FSCS\n",
       "15        Random Forest  0.797531   0.804078  0.797531  0.797543        FSCS\n",
       "13    Gradient Boosting  0.767901   0.771343  0.767901  0.767184        FSCS\n",
       "14                  KNN  0.718519   0.729093  0.718519  0.714802        FSCS\n",
       "16        Decision Tree  0.708642   0.705515  0.708642  0.705657        FSCS\n",
       "30  Logistic Regression  0.817284   0.818823  0.817284  0.817552          MI\n",
       "35                  SVM  0.814815   0.816174  0.814815  0.814977          MI\n",
       "31    Gradient Boosting  0.772840   0.774527  0.772840  0.772246          MI\n",
       "33        Random Forest  0.770370   0.772990  0.770370  0.770124          MI\n",
       "32                  KNN  0.730864   0.736358  0.730864  0.726129          MI\n",
       "34        Decision Tree  0.664198   0.660441  0.664198  0.661185          MI\n",
       "36  Logistic Regression  0.839506   0.842813  0.839506  0.839901         MIR\n",
       "41                  SVM  0.819753   0.822455  0.819753  0.819837         MIR\n",
       "39        Random Forest  0.790123   0.790346  0.790123  0.789713         MIR\n",
       "37    Gradient Boosting  0.785185   0.786896  0.785185  0.785659         MIR\n",
       "38                  KNN  0.708642   0.711831  0.708642  0.705962         MIR\n",
       "40        Decision Tree  0.671605   0.669497  0.671605  0.670138         MIR\n",
       "42  Logistic Regression  0.800000   0.801515  0.800000  0.799689          MU\n",
       "47                  SVM  0.787654   0.790187  0.787654  0.787359          MU\n",
       "43    Gradient Boosting  0.782716   0.782644  0.782716  0.782141          MU\n",
       "45        Random Forest  0.755556   0.763907  0.755556  0.758346          MU\n",
       "46        Decision Tree  0.683951   0.682719  0.683951  0.683274          MU\n",
       "44                  KNN  0.664198   0.666898  0.664198  0.663362          MU\n",
       "24  Logistic Regression  0.824691   0.825921  0.824691  0.824633          PC\n",
       "29                  SVM  0.817284   0.817684  0.817284  0.816995          PC\n",
       "27        Random Forest  0.782716   0.785805  0.782716  0.782173          PC\n",
       "25    Gradient Boosting  0.762963   0.763578  0.762963  0.761818          PC\n",
       "26                  KNN  0.701235   0.714955  0.701235  0.694517          PC\n",
       "28        Decision Tree  0.659259   0.658831  0.659259  0.658298          PC\n",
       "5                   SVM  0.817284   0.819584  0.817284  0.817786         RFE\n",
       "0   Logistic Regression  0.814815   0.815649  0.814815  0.815028         RFE\n",
       "3         Random Forest  0.792593   0.795209  0.792593  0.793446         RFE\n",
       "1     Gradient Boosting  0.787654   0.790931  0.787654  0.787384         RFE\n",
       "2                   KNN  0.706173   0.708551  0.706173  0.704403         RFE\n",
       "4         Decision Tree  0.666667   0.663335  0.666667  0.664280         RFE\n",
       "6   Logistic Regression  0.817284   0.818823  0.817284  0.817552         SKB\n",
       "11                  SVM  0.814815   0.816174  0.814815  0.814977         SKB\n",
       "9         Random Forest  0.780247   0.781573  0.780247  0.780244         SKB\n",
       "7     Gradient Boosting  0.772840   0.774527  0.772840  0.772246         SKB\n",
       "8                   KNN  0.730864   0.736358  0.730864  0.726129         SKB\n",
       "10        Decision Tree  0.676543   0.675238  0.676543  0.675615         SKB\n",
       "48  Logistic Regression  0.827160   0.831195  0.827160  0.827344          VT\n",
       "53                  SVM  0.802469   0.805783  0.802469  0.802461          VT\n",
       "49    Gradient Boosting  0.780247   0.783048  0.780247  0.780933          VT\n",
       "51        Random Forest  0.765432   0.769560  0.765432  0.765347          VT\n",
       "50                  KNN  0.730864   0.736353  0.730864  0.728945          VT\n",
       "52        Decision Tree  0.661728   0.671372  0.661728  0.664488          VT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined model summary saved → ..\\data\\processed\\ml1\\all_model_results_summary_v2.csv\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for method in METHODS:\n",
    "    res_path = PROC_BASE / method / \"results_traditional_ml.csv\"\n",
    "    if res_path.exists():\n",
    "        df = pd.read_csv(res_path)\n",
    "        df[\"Feature Set\"] = method.upper()\n",
    "        all_results.append(df)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing results for {method.upper()}\")\n",
    "\n",
    "if all_results:\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    combined_results = combined_results.sort_values([\"Feature Set\", \"Accuracy\"], ascending=[True, False])\n",
    "    \n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    display(combined_results)\n",
    "\n",
    "    summary_out = PROC_BASE / \"all_model_results_summary_v2.csv\"\n",
    "    combined_results.to_csv(summary_out, index=False)\n",
    "    print(f\"✅ Combined model summary saved → {summary_out}\")\n",
    "else:\n",
    "    print(\"⚠️ No model results found. Please run training first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
