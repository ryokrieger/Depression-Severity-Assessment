{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7df389",
   "metadata": {},
   "source": [
    "# Model Training (Machine Learning)\n",
    "\n",
    "We train **6 traditional ML classifiers** on nine feature-selection datasets:\n",
    "\n",
    "1. **Logistic Regression**\n",
    "2. **Gradient Boosting Classifier**\n",
    "3. **K-Nearest Neighbours**\n",
    "4. **Random Forest Classifier**\n",
    "5. **Decision Tree Classifier**\n",
    "6. **Support Vector Machine**\n",
    "\n",
    "Metrics → `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals → Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c1edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "BASE_DIR = Path.cwd().parents[1]\n",
    "FEATURES_BASE = BASE_DIR / \"features\" / \"03 - Third Working\"\n",
    "PROC_BASE = BASE_DIR / \"results\" / \"03 - Third Working\" / \"Machine Learning\"\n",
    "MODEL_BASE = BASE_DIR / \"models\" / \"03 - Third Working\" / \"Machine Learning\"\n",
    "FIG_BASE = BASE_DIR / \"figures\" / \"03 - Third Working\" / \"Machine Learning\"\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba050ef",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8264",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"SVM\": SVC(probability=True, random_state=RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af3e1",
   "metadata": {},
   "source": [
    "## Train All Six Models Across Nine Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0ac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Training ML models for: RFE\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for RFE to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\03 - Third Working\\Machine Learning\\rfe\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: SKB\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for SKB to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\03 - Third Working\\Machine Learning\\skb\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: FSCS\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for FSCS to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\03 - Third Working\\Machine Learning\\fscs\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: ETC\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for ETC to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\03 - Third Working\\Machine Learning\\etc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: PC\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for PC to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\03 - Third Working\\Machine Learning\\pc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MI\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MI to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\03 - Third Working\\Machine Learning\\mi\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MIR\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MIR to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\03 - Third Working\\Machine Learning\\mir\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MU\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MU to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\03 - Third Working\\Machine Learning\\mu\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: VT\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for VT to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\03 - Third Working\\Machine Learning\\vt\\results_traditional_ml.csv\n"
     ]
    }
   ],
   "source": [
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ Training ML models for: {method.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    train_path = in_dir / \"train.csv\"\n",
    "    test_path = in_dir / \"test.csv\"\n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        print(f\"⚠️ Missing train/test for {method}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    train_df = train_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = test_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "    results = []\n",
    "    proc_out = PROC_BASE / method\n",
    "    model_out = MODEL_BASE / method\n",
    "    fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name, model in MODELS.items():\n",
    "        print(f\" - Training {name} ...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics = compute_metrics(y_test, y_pred)\n",
    "        metrics_row = {\"Model\": name, **metrics}\n",
    "        results.append(metrics_row)\n",
    "\n",
    "        cm_path = fig_out / f\"{name.lower().replace(' ', '_')}_confusion.png\"\n",
    "        plot_and_save_confusion(y_test, y_pred, cm_path, f\"{name} Confusion ({method.upper()})\")\n",
    "\n",
    "        model_path = model_out / f\"{name.lower().replace(' ', '_')}.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    res_df.to_csv(proc_out / \"results_traditional_ml.csv\", index=False)\n",
    "    print(f\"✅ Saved results for {method.upper()} to {proc_out / 'results_traditional_ml.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a2308",
   "metadata": {},
   "source": [
    "## Summary of Model Performance Across All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207b3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.829630</td>\n",
       "      <td>0.829350</td>\n",
       "      <td>0.829630</td>\n",
       "      <td>0.828962</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.804751</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.803428</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.794636</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.792759</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.784123</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.784299</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>0.755623</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>0.754759</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.676543</td>\n",
       "      <td>0.674202</td>\n",
       "      <td>0.676543</td>\n",
       "      <td>0.673490</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.821020</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.802388</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799395</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.792900</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789928</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.791295</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.785900</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.757087</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.751256</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.721535</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.720287</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817648</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.816656</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.815058</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.798604</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.795124</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.781352</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777578</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.766457</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.760203</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.686420</td>\n",
       "      <td>0.685586</td>\n",
       "      <td>0.686420</td>\n",
       "      <td>0.683690</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.857957</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.856399</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.828093</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.824909</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.807197</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.807219</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.778743</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.778052</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>0.758623</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>0.757193</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.695960</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.798953</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.796810</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.795591</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.791705</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.773339</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.771138</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.766494</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.764637</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.707398</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.703163</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>0.699114</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>0.697033</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.825681</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.824491</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.813484</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.812269</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.791632</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789638</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.778563</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.775753</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.752910</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.748976</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.677308</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.676996</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.828519</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.827191</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.826327</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.794462</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.792647</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.791971</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.790125</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.786104</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.783874</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.686420</td>\n",
       "      <td>0.685831</td>\n",
       "      <td>0.686420</td>\n",
       "      <td>0.685844</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.817648</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.816656</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.815058</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.798604</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.795124</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.778747</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.775235</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.766457</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.760203</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.674055</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.674566</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.827288</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.814160</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.806402</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.787280</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.784083</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.779654</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.776077</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.741229</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.737891</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.671605</td>\n",
       "      <td>0.674565</td>\n",
       "      <td>0.671605</td>\n",
       "      <td>0.672840</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall        F1 Feature Set\n",
       "18  Logistic Regression  0.829630   0.829350  0.829630  0.828962         ETC\n",
       "23                  SVM  0.804938   0.804751  0.804938  0.803428         ETC\n",
       "21        Random Forest  0.792593   0.794636  0.792593  0.792759         ETC\n",
       "19    Gradient Boosting  0.785185   0.784123  0.785185  0.784299         ETC\n",
       "20                  KNN  0.758025   0.755623  0.758025  0.754759         ETC\n",
       "22        Decision Tree  0.676543   0.674202  0.676543  0.673490         ETC\n",
       "12  Logistic Regression  0.817284   0.821020  0.817284  0.817808        FSCS\n",
       "17                  SVM  0.800000   0.802388  0.800000  0.799395        FSCS\n",
       "15        Random Forest  0.790123   0.792900  0.790123  0.789928        FSCS\n",
       "13    Gradient Boosting  0.787654   0.791295  0.787654  0.785900        FSCS\n",
       "14                  KNN  0.750617   0.757087  0.750617  0.751256        FSCS\n",
       "16        Decision Tree  0.723457   0.721535  0.723457  0.720287        FSCS\n",
       "30  Logistic Regression  0.817284   0.819935  0.817284  0.817648          MI\n",
       "35                  SVM  0.814815   0.816656  0.814815  0.815058          MI\n",
       "31    Gradient Boosting  0.795062   0.798604  0.795062  0.795124          MI\n",
       "33        Random Forest  0.777778   0.781352  0.777778  0.777578          MI\n",
       "32                  KNN  0.760494   0.766457  0.760494  0.760203          MI\n",
       "34        Decision Tree  0.686420   0.685586  0.686420  0.683690          MI\n",
       "36  Logistic Regression  0.856790   0.857957  0.856790  0.856399         MIR\n",
       "41                  SVM  0.824691   0.828093  0.824691  0.824909         MIR\n",
       "37    Gradient Boosting  0.807407   0.807197  0.807407  0.807219         MIR\n",
       "39        Random Forest  0.777778   0.778743  0.777778  0.778052         MIR\n",
       "38                  KNN  0.758025   0.758623  0.758025  0.757193         MIR\n",
       "40        Decision Tree  0.693827   0.695960  0.693827  0.694581         MIR\n",
       "42  Logistic Regression  0.797531   0.798953  0.797531  0.796810          MU\n",
       "45        Random Forest  0.790123   0.795591  0.790123  0.791705          MU\n",
       "43    Gradient Boosting  0.770370   0.773339  0.770370  0.771138          MU\n",
       "47                  SVM  0.765432   0.766494  0.765432  0.764637          MU\n",
       "44                  KNN  0.703704   0.707398  0.703704  0.703163          MU\n",
       "46        Decision Tree  0.696296   0.699114  0.696296  0.697033          MU\n",
       "24  Logistic Regression  0.824691   0.825681  0.824691  0.824491          PC\n",
       "29                  SVM  0.812346   0.813484  0.812346  0.812269          PC\n",
       "25    Gradient Boosting  0.790123   0.791632  0.790123  0.789638          PC\n",
       "27        Random Forest  0.775309   0.778563  0.775309  0.775753          PC\n",
       "26                  KNN  0.750617   0.752910  0.750617  0.748976          PC\n",
       "28        Decision Tree  0.679012   0.677308  0.679012  0.676996          PC\n",
       "5                   SVM  0.827160   0.828519  0.827160  0.827191         RFE\n",
       "0   Logistic Regression  0.824691   0.826327  0.824691  0.825150         RFE\n",
       "1     Gradient Boosting  0.792593   0.794462  0.792593  0.792647         RFE\n",
       "3         Random Forest  0.790123   0.791971  0.790123  0.790125         RFE\n",
       "2                   KNN  0.785185   0.786104  0.785185  0.783874         RFE\n",
       "4         Decision Tree  0.686420   0.685831  0.686420  0.685844         RFE\n",
       "6   Logistic Regression  0.817284   0.819935  0.817284  0.817648         SKB\n",
       "11                  SVM  0.814815   0.816656  0.814815  0.815058         SKB\n",
       "7     Gradient Boosting  0.795062   0.798604  0.795062  0.795124         SKB\n",
       "9         Random Forest  0.775309   0.778747  0.775309  0.775235         SKB\n",
       "8                   KNN  0.760494   0.766457  0.760494  0.760203         SKB\n",
       "10        Decision Tree  0.679012   0.674055  0.679012  0.674566         SKB\n",
       "48  Logistic Regression  0.827160   0.830698  0.827160  0.827288          VT\n",
       "53                  SVM  0.807407   0.814160  0.807407  0.806402          VT\n",
       "49    Gradient Boosting  0.782716   0.787280  0.782716  0.784083          VT\n",
       "51        Random Forest  0.775309   0.779654  0.775309  0.776077          VT\n",
       "50                  KNN  0.738272   0.741229  0.738272  0.737891          VT\n",
       "52        Decision Tree  0.671605   0.674565  0.671605  0.672840          VT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined model summary saved → d:\\Programming\\Projects\\Depression Severity Assessment\\summary\\results\\Results Summary (ML)\\third_working_results_summary\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for method in METHODS:\n",
    "    res_path = PROC_BASE / method / \"results_traditional_ml.csv\"\n",
    "    if res_path.exists():\n",
    "        df = pd.read_csv(res_path)\n",
    "        df[\"Feature Set\"] = method.upper()\n",
    "        all_results.append(df)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing results for {method.upper()}\")\n",
    "\n",
    "if all_results:\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    combined_results = combined_results.sort_values([\"Feature Set\", \"Accuracy\"], ascending=[True, False])\n",
    "    \n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    display(combined_results)\n",
    "\n",
    "    summary_out = BASE_DIR / \"summary\" / \"results\" / \"Results Summary (ML)\" / \"third_working_results_summary\"\n",
    "    combined_results.to_csv(summary_out, index=False)\n",
    "    print(f\"✅ Combined model summary saved → {summary_out}\")\n",
    "else:\n",
    "    print(\"⚠️ No model results found. Please run training first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
