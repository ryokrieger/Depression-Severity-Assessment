{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8af9ba4",
   "metadata": {},
   "source": [
    "# Model Training (Deep Learning)\n",
    "\n",
    "We train two deep learning models (ANN and 1D-CNN) on each of the nine feature-selection datasets.\n",
    "\n",
    "For each method and model we:\n",
    "- Train on 80% train split and evaluate on the provided test split.\n",
    "- Compute Accuracy, Precision, Recall, F1.\n",
    "- Save the Confusion Matrix (PNG) and Accuracy vs Epoch plot (PNG).\n",
    "- Save the trained model (.h5).\n",
    "- Save results CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21041496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "FEATURES_BASE = Path(\"../data/processed/features2\")\n",
    "PROC_BASE = Path(\"../data/processed/dl2\")\n",
    "MODEL_BASE = Path(\"../models/dl2\")\n",
    "FIG_BASE = Path(\"../figures/dl2\")\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ed4a4",
   "metadata": {},
   "source": [
    "## Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f45efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ann(input_dim, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn(input_dim, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Reshape((input_dim, 1)),\n",
    "        layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(32, 3, activation='relu', padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5cc38",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e606464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title(title); ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "def save_accuracy_plot(history, path, title):\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.plot(history.history.get('accuracy', []), label='Train Acc')\n",
    "    ax.plot(history.history.get('val_accuracy', []), label='Val Acc')\n",
    "    ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"Accuracy\"); ax.set_title(title); ax.legend()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e405e7",
   "metadata": {},
   "source": [
    "## Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbff7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(method, model_type, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE):\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    if not in_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {in_dir}\")\n",
    "\n",
    "    train_df = pd.read_csv(in_dir / \"train.csv\").dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = pd.read_csv(in_dir / \"test.csv\").dropna(subset=[\"DepressionEncoded\"])\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"]).values.astype(np.float32)\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int).values\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"]).values.astype(np.float32)\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int).values\n",
    "\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train_oh = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_oh = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    model = build_ann(input_dim, num_classes) if model_type == \"ANN\" else build_cnn(input_dim, num_classes)\n",
    "\n",
    "    es = callbacks.EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=0)\n",
    "    history = model.fit(X_train, y_train_oh, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[es], verbose=verbose)\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    metrics = compute_metrics(y_test, y_pred)\n",
    "\n",
    "    proc_out = PROC_BASE / method; model_out = MODEL_BASE / method; fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_file = model_out / f\"{model_type.lower()}_model.h5\"\n",
    "    model.save(model_file)\n",
    "\n",
    "    save_confusion(y_test, y_pred, fig_out / f\"{model_type.lower()}_confusion.png\", f\"{model_type} Confusion ({method})\")\n",
    "    save_accuracy_plot(history, fig_out / f\"{model_type.lower()}_accuracy.png\", f\"{model_type} Accuracy vs Epoch ({method})\")\n",
    "\n",
    "    res_file = proc_out / \"results_deep_learning.csv\"\n",
    "    row = pd.DataFrame([{\"Method\": method, \"Model\": model_type, **metrics}])\n",
    "    if res_file.exists():\n",
    "        row.to_csv(res_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        row.to_csv(res_file, index=False)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042f56e",
   "metadata": {},
   "source": [
    "## Run ANN and CNN for All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b73fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = []\n",
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ DL training for: {method.upper()}\")\n",
    "    for model_type in [\"ANN\",\"CNN\"]:\n",
    "        try:\n",
    "            print(f\" - Training {model_type}\")\n",
    "            metrics = train_and_save(method, model_type)\n",
    "            results_all.append({\"Method\": method, \"Model\": model_type, **metrics})\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error for {method} {model_type}: {e}\")\n",
    "\n",
    "combined = pd.DataFrame(results_all)\n",
    "combined_out = PROC_BASE / \"all_deep_learning_results_summary_v3.csv\"\n",
    "combined.to_csv(combined_out, index=False)\n",
    "print(\"✅ DL combined summary saved to:\", combined_out)\n",
    "display(combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
