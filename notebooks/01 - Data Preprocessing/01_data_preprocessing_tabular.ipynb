{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190b28ba",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook cleans and standardizes the **MHP dataset** for modelling.  \n",
    "\n",
    "Steps performed:\n",
    "1. Rename demographic columns and normalize their values\n",
    "2. Rename and recode **PSS-10 (Stress)** items\n",
    "3. Rename and recode **GAD-7 (Anxiety)** items\n",
    "4. Rename and recode **PHQ-9 (Depression)** items\n",
    "5. Create `Depression Value` (PHQ-9 sum) and categorical `Depression Label`\n",
    "6. Check for missing & duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "BASE_DIR = Path.cwd().parents[1]\n",
    "RAW_PATH = BASE_DIR / \"data\" / \"raw\" / \"mhp_dataset.csv\"\n",
    "PROCESSED_PATH = BASE_DIR / \"data\" / \"processed\" / \"tabular\" / \"mhp_processed.csv\"\n",
    "\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "print(\"Shape before processing:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5d1fb7",
   "metadata": {},
   "source": [
    "## Demographic columns cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_demo_names = [\n",
    "    \"Age\", \"Gender\", \"University\", \"Department\",\n",
    "    \"Year\", \"CGPA\", \"Scholarship\"\n",
    "]\n",
    "df.rename(columns=dict(zip(df.columns[:7], new_demo_names)), inplace=True)\n",
    "\n",
    "df[\"Gender\"] = df[\"Gender\"].replace({\n",
    "    \"Prefer not to say\": \"Other\",\n",
    "    \"prefer not to say\": \"Other\"\n",
    "}).str.title()\n",
    "\n",
    "def extract_initials(text):\n",
    "    if isinstance(text, str):\n",
    "        m = re.search(r\"\\(([^)]+)\\)\", text)\n",
    "        if m:\n",
    "            return m.group(1).strip()\n",
    "        else:\n",
    "            return text.strip().split()[0]\n",
    "    return text\n",
    "\n",
    "df[\"University\"] = df[\"University\"].apply(extract_initials)\n",
    "\n",
    "df[\"Department\"] = df[\"Department\"].astype(str).str.split().str[0]\n",
    "\n",
    "df[\"Year\"] = df[\"Year\"].astype(str).str.split().str[0]\n",
    "\n",
    "df[\"Scholarship\"] = df[\"Scholarship\"].replace({\n",
    "    \"Yes, full waiver\": \"Yes\",\n",
    "    \"Yes, partial waiver\": \"Yes\",\n",
    "    \"No waiver\": \"No\"\n",
    "}).fillna(\"No\")\n",
    "\n",
    "df[new_demo_names].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51294b",
   "metadata": {},
   "source": [
    "## PSS-10 (Stress) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5bef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pss_cols = df.columns[7:17]\n",
    "df.rename(columns=dict(zip(pss_cols, [f\"PSS{i+1}\" for i in range(10)])), inplace=True)\n",
    "\n",
    "pss_map = {\n",
    "    \"0 - Never\": 0,\n",
    "    \"1 - Almost Never\": 1,\n",
    "    \"2 - Sometimes\": 2,\n",
    "    \"3 - Fairly Often\": 3,\n",
    "    \"4 - Very Often\": 4\n",
    "}\n",
    "\n",
    "for c in [f\"PSS{i+1}\" for i in range(10)]:\n",
    "    df[c] = df[c].replace(pss_map)\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df[[f\"PSS{i+1}\" for i in range(10)]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98a410",
   "metadata": {},
   "source": [
    "## GAD-7 (Anxiety) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d24bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "gad_cols = df.columns[17:24]\n",
    "df.rename(columns=dict(zip(gad_cols, [f\"GAD{i+1}\" for i in range(7)])), inplace=True)\n",
    "\n",
    "gad_map = {\n",
    "    \"0 - Not at all\": 0,\n",
    "    \"1 - Several days (less than 15 days)\": 1,\n",
    "    \"1 - Several days\": 1,\n",
    "    \"2 - More than half the semester\": 2,\n",
    "    \"2 - More than half the days\": 2,\n",
    "    \"3 - Nearly every day\": 3\n",
    "}\n",
    "\n",
    "for c in [f\"GAD{i+1}\" for i in range(7)]:\n",
    "    df[c] = df[c].replace(gad_map)\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df[[f\"GAD{i+1}\" for i in range(7)]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47c5c58",
   "metadata": {},
   "source": [
    "## PHQ-9 (Depression) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09144e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "phq_cols = df.columns[24:33]\n",
    "df.rename(columns=dict(zip(phq_cols, [f\"PHQ{i+1}\" for i in range(9)])), inplace=True)\n",
    "\n",
    "phq_map = {\n",
    "    \"0 - Not at all\": 0,\n",
    "    \"1 - Several days\": 1,\n",
    "    \"2 - More than half the days\": 2,\n",
    "    \"3 - Nearly every day\": 3\n",
    "}\n",
    "\n",
    "for c in [f\"PHQ{i+1}\" for i in range(9)]:\n",
    "    df[c] = df[c].replace(phq_map)\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df[\"Depression Value\"] = df[[f\"PHQ{i+1}\" for i in range(9)]].sum(axis=1)\n",
    "\n",
    "def phq_label(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    if val <= 4:\n",
    "        return \"Minimal\"\n",
    "    elif val <= 9:\n",
    "        return \"Mild\"\n",
    "    elif val <= 14:\n",
    "        return \"Moderate\"\n",
    "    elif val <= 19:\n",
    "        return \"Moderately Severe\"\n",
    "    else:\n",
    "        return \"Severe\"\n",
    "\n",
    "df[\"Depression Label\"] = df[\"Depression Value\"].apply(phq_label)\n",
    "\n",
    "display_cols = [f\"PHQ{i+1}\" for i in range(9)] + [\"Depression Value\", \"Depression Label\"]\n",
    "df[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6fca03",
   "metadata": {},
   "source": [
    "## Data Quality Checks — Missing & Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset info before cleaning:\\n\")\n",
    "print(df.info())\n",
    "\n",
    "missing_counts = df.isna().sum()\n",
    "missing_total = missing_counts.sum()\n",
    "\n",
    "print(\"\\nMissing values summary:\")\n",
    "print(missing_counts[missing_counts > 0].sort_values(ascending=False))\n",
    "\n",
    "if missing_total > 0:\n",
    "    print(f\"\\n⚠️ Found {missing_total} missing values. Handling them now...\")\n",
    "\n",
    "    num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "    df[num_cols] = df[num_cols].apply(lambda col: col.fillna(col.median()))\n",
    "    df[cat_cols] = df[cat_cols].apply(lambda col: col.fillna(col.mode()[0] if not col.mode().empty else \"Unknown\"))\n",
    "\n",
    "    print(\"✅ Missing values handled (numeric → median, categorical → mode).\")\n",
    "else:\n",
    "    print(\"\\n✅ No missing values found.\")\n",
    "\n",
    "dup_count = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows found: {dup_count}\")\n",
    "\n",
    "if dup_count > 0:\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    print(f\"✅ Removed {dup_count} duplicate rows.\")\n",
    "else:\n",
    "    print(\"✅ No duplicate rows found.\")\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nDepression label distribution:\")\n",
    "print(df[\"Depression Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41562e16",
   "metadata": {},
   "source": [
    "## Remove Derived Columns to Prevent Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1f4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Depression Value\" in df.columns:\n",
    "    df.drop(columns=[\"Depression Value\"], inplace=True)\n",
    "    print(\"✅ 'Depression Value' column removed to prevent overfitting.\")\n",
    "else:\n",
    "    print(\"ℹ️ 'Depression Value' column already removed or not found.\")\n",
    "\n",
    "print(f\"Remaining columns ({len(df.columns)}):\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b1271",
   "metadata": {},
   "source": [
    "## Save processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc07fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(PROCESSED_PATH, index=False)\n",
    "print(f\"Processed dataset saved to: {PROCESSED_PATH.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
