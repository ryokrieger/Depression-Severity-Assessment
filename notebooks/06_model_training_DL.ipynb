{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8af9ba4",
   "metadata": {},
   "source": [
    "# Model Training (Deep Learning)\n",
    "\n",
    "We train two deep learning models (ANN and 1D-CNN) on each of the nine feature-selection datasets.\n",
    "\n",
    "For each method and model we:\n",
    "- Train on 80% train split and evaluate on the provided test split.\n",
    "- Compute Accuracy, Precision, Recall, F1.\n",
    "- Save the Confusion Matrix (PNG) and Accuracy vs Epoch plot (PNG).\n",
    "- Save the trained model (.h5).\n",
    "- Save results CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21041496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "FEATURES_BASE = Path(\"../data/processed/features\")\n",
    "PROC_BASE = Path(\"../data/processed/dl\")\n",
    "MODEL_BASE = Path(\"../models/dl\")\n",
    "FIG_BASE = Path(\"../figures/dl\")\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ed4a4",
   "metadata": {},
   "source": [
    "## Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f45efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ann(input_dim, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn(input_dim, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Reshape((input_dim, 1)),\n",
    "        layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(32, 3, activation='relu', padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5cc38",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e606464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_accuracy_plot(history, path, title):\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.plot(history.history.get('accuracy', []), label='Train Acc')\n",
    "    ax.plot(history.history.get('val_accuracy', []), label='Val Acc')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e405e7",
   "metadata": {},
   "source": [
    "## Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fbff7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(method, model_type, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE):\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    if not in_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing feature-set: {in_dir}\")\n",
    "\n",
    "    train_df = pd.read_csv(in_dir / \"train.csv\").dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = pd.read_csv(in_dir / \"test.csv\").dropna(subset=[\"DepressionEncoded\"])\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"]).values.astype(np.float32)\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int).values\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"]).values.astype(np.float32)\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int).values\n",
    "\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train_oh = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_oh = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    if model_type == \"ANN\":\n",
    "        model = build_ann(input_dim, num_classes)\n",
    "    else:\n",
    "        model = build_cnn(input_dim, num_classes)\n",
    "\n",
    "    es = callbacks.EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True, mode='max', verbose=0)\n",
    "\n",
    "    history = model.fit(X_train, y_train_oh, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[es], verbose=verbose)\n",
    "\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    metrics = compute_metrics(y_test, y_pred)\n",
    "\n",
    "    proc_out = PROC_BASE / method\n",
    "    model_out = MODEL_BASE / method\n",
    "    fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_file = model_out / f\"{model_type.lower()}_model.h5\"\n",
    "    model.save(model_file)\n",
    "\n",
    "    save_confusion(y_test, y_pred, fig_out / f\"{model_type.lower()}_confusion.png\", f\"{model_type} Confusion ({method})\")\n",
    "    save_accuracy_plot(history, fig_out / f\"{model_type.lower()}_accuracy.png\", f\"{model_type} Accuracy vs Epoch ({method})\")\n",
    "\n",
    "    res_file = proc_out / \"results_deep_learning.csv\"\n",
    "    row = pd.DataFrame([{\"Method\": method, \"Model\": model_type, **metrics}])\n",
    "    if res_file.exists():\n",
    "        row.to_csv(res_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        row.to_csv(res_file, index=False)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042f56e",
   "metadata": {},
   "source": [
    "## Run ANN and CNN for All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8b73fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: RFE\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: SKB\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: FSCS\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: ETC\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: PC\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: MI\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: MIR\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: MU\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: VT\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Completed DL training. Summary saved to: ..\\data\\processed\\dl\\all_deep_learning_results_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfe</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.762773</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.748158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfe</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.763327</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.760442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skb</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.748076</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.743387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skb</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.754255</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.745421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fscs</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.720988</td>\n",
       "      <td>0.728871</td>\n",
       "      <td>0.720988</td>\n",
       "      <td>0.717836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fscs</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.743729</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.731910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>etc</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.765420</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.763396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>etc</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.783777</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.768656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pc</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.761390</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.759611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pc</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.771580</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.770096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mi</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.763243</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.755570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mi</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.738684</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.731034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mir</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.746395</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.746100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mir</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.764971</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.762611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mu</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.707034</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.707989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mu</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.756496</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.745971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vt</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.779157</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.777685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vt</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797995</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Method Model  Accuracy  Precision    Recall        F1\n",
       "0     rfe   ANN  0.753086   0.762773  0.753086  0.748158\n",
       "1     rfe   CNN  0.760494   0.763327  0.760494  0.760442\n",
       "2     skb   ANN  0.748148   0.748076  0.748148  0.743387\n",
       "3     skb   CNN  0.743210   0.754255  0.743210  0.745421\n",
       "4    fscs   ANN  0.720988   0.728871  0.720988  0.717836\n",
       "5    fscs   CNN  0.730864   0.743729  0.730864  0.731910\n",
       "6     etc   ANN  0.767901   0.765420  0.767901  0.763396\n",
       "7     etc   CNN  0.767901   0.783777  0.767901  0.768656\n",
       "8      pc   ANN  0.762963   0.761390  0.762963  0.759611\n",
       "9      pc   CNN  0.770370   0.771580  0.770370  0.770096\n",
       "10     mi   ANN  0.760494   0.763243  0.760494  0.755570\n",
       "11     mi   CNN  0.728395   0.738684  0.728395  0.731034\n",
       "12    mir   ANN  0.748148   0.746395  0.748148  0.746100\n",
       "13    mir   CNN  0.762963   0.764971  0.762963  0.762611\n",
       "14     mu   ANN  0.711111   0.707034  0.711111  0.707989\n",
       "15     mu   CNN  0.743210   0.756496  0.743210  0.745971\n",
       "16     vt   ANN  0.780247   0.779157  0.780247  0.777685\n",
       "17     vt   CNN  0.797531   0.797995  0.797531  0.797130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_all = []\n",
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ Deep learning for: {method.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    for model_type in [\"ANN\", \"CNN\"]:\n",
    "        try:\n",
    "            print(f\" - Training {model_type} ...\")\n",
    "            m = train_and_save(method, model_type)\n",
    "            results_all.append({\"Method\": method, \"Model\": model_type, **m})\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error for {method} {model_type}: {e}\")\n",
    "\n",
    "combined = pd.DataFrame(results_all)\n",
    "combined.to_csv(PROC_BASE / \"all_deep_learning_results_summary.csv\", index=False)\n",
    "print(\"\\n✅ Completed DL training. Summary saved to:\", PROC_BASE / \"all_deep_learning_results_summary.csv\")\n",
    "display(combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
