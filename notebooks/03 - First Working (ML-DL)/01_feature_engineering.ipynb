{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9e8740",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "In this notebook we create **9 feature sets** from the processed dataset:\n",
    "\n",
    "1. **Recursive Feature Elimination**\n",
    "2. **Select K Best**\n",
    "3. **Fisher Score Chi-Square**\n",
    "4. **Extra Trees Classifier**\n",
    "5. **Pearson Correlation**\n",
    "6. **Mutual Information**\n",
    "7. **Mutual Info Regression**\n",
    "8. **Manual Uniqueness**\n",
    "9. **Variance Threshold**\n",
    "\n",
    "For each method select:\n",
    "- 5 features from PSS-10\n",
    "- 5 features from GAD-7\n",
    "- 5 features from PHQ-9\n",
    "\n",
    "Combine to 15 features ‚Üí standardize\n",
    "\n",
    "We then split the data (80/20, stratified) for model training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fceb834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import (\n",
    "    RFE, SelectKBest, chi2, VarianceThreshold, f_classif,\n",
    "    mutual_info_classif, mutual_info_regression\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "BASE_DIR = Path.cwd().parents[1]\n",
    "DATA_IN = BASE_DIR / \"data\" / \"processed\" / \"tabular\" / \"mhp_processed.csv\"\n",
    "OUT_BASE = BASE_DIR / \"features\" / \"First Working\"\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUMMARY_PATH = BASE_DIR / \"summary\" / \"features\" / \"first_working_features_summary\"\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f815c636",
   "metadata": {},
   "source": [
    "## Load and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345405b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_IN)\n",
    "print(\"Loaded:\", DATA_IN, \"shape:\", df.shape)\n",
    "\n",
    "pss_cols = [c for c in df.columns if c.upper().startswith(\"PSS\")]\n",
    "gad_cols = [c for c in df.columns if c.upper().startswith(\"GAD\")]\n",
    "phq_cols = [c for c in df.columns if c.upper().startswith(\"PHQ\")]\n",
    "\n",
    "print(\"Detected columns counts:\", len(pss_cols), len(gad_cols), len(phq_cols))\n",
    "print(\"PSS cols:\", pss_cols)\n",
    "print(\"GAD cols:\", gad_cols)\n",
    "print(\"PHQ cols:\", phq_cols)\n",
    "\n",
    "if \"DepressionEncoded\" not in df.columns or df[\"DepressionEncoded\"].isna().sum() > 0:\n",
    "    df_phq = df[phq_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    phq_sum = df_phq.sum(axis=1)\n",
    "    df[\"DepressionEncoded\"] = pd.cut(\n",
    "        phq_sum,\n",
    "        bins=[-1, 4, 9, 14, 19, 27],\n",
    "        labels=[0,1,2,3,4]\n",
    "    ).astype(int)\n",
    "print(\"Target distribution (DepressionEncoded):\")\n",
    "print(df[\"DepressionEncoded\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78536844",
   "metadata": {},
   "source": [
    "## Feature Selection Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958fbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_rfe(X, y, k):\n",
    "    model = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "    sel = RFE(model, n_features_to_select=k)\n",
    "    sel.fit(X, y)\n",
    "    return X.columns[sel.support_].tolist()\n",
    "\n",
    "def select_skb(X, y, k):\n",
    "    sel = SelectKBest(score_func=f_classif, k=k)\n",
    "    sel.fit(X.fillna(0), y)\n",
    "    return X.columns[sel.get_support()].tolist()\n",
    "\n",
    "def select_fscs(X, y, k):\n",
    "    Xn = X.copy()\n",
    "    Xn = Xn - Xn.min()\n",
    "    sel = SelectKBest(score_func=chi2, k=k)\n",
    "    sel.fit(Xn.fillna(0).astype(int), y)\n",
    "    return X.columns[sel.get_support()].tolist()\n",
    "\n",
    "def select_etc(X, y, k):\n",
    "    model = ExtraTreesClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
    "    model.fit(X.fillna(0), y)\n",
    "    importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    return importances.nlargest(k).index.tolist()\n",
    "\n",
    "def select_pc(X, y, k):\n",
    "    scores = []\n",
    "    for c in X.columns:\n",
    "        try:\n",
    "            r = pearsonr(X[c].fillna(X[c].mean()), y)[0]\n",
    "        except Exception:\n",
    "            r = 0.0\n",
    "        scores.append((abs(r), c))\n",
    "    scores.sort(reverse=True)\n",
    "    return [c for _, c in scores[:k]]\n",
    "\n",
    "def select_mi(X, y, k):\n",
    "    scores = mutual_info_classif(X.fillna(0), y, random_state=RANDOM_STATE)\n",
    "    order = np.argsort(scores)[::-1][:k]\n",
    "    return X.columns[order].tolist()\n",
    "\n",
    "def select_mir(X, y, k):\n",
    "    scores = mutual_info_regression(X.fillna(0), y, random_state=RANDOM_STATE)\n",
    "    order = np.argsort(scores)[::-1][:k]\n",
    "    return X.columns[order].tolist()\n",
    "\n",
    "def select_mu(X, y, k):\n",
    "    uniq = X.nunique().sort_values(ascending=False)\n",
    "    return uniq.head(k).index.tolist()\n",
    "\n",
    "def select_vt(X, y, k):\n",
    "    var = X.var().sort_values(ascending=False)\n",
    "    return var.head(k).index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be915054",
   "metadata": {},
   "source": [
    "## Run all nine feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"rfe\": select_rfe,\n",
    "    \"skb\": select_skb,\n",
    "    \"fscs\": select_fscs,\n",
    "    \"etc\": select_etc,\n",
    "    \"pc\": select_pc,\n",
    "    \"mi\": select_mi,\n",
    "    \"mir\": select_mir,\n",
    "    \"mu\": select_mu,\n",
    "    \"vt\": select_vt\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "for name, func in methods.items():\n",
    "    print(f\"\\n‚û° Running method: {name.upper()}\")\n",
    "\n",
    "    selected = []\n",
    "    sel_pss = func(df[pss_cols], df[\"DepressionEncoded\"], k=5)\n",
    "    sel_gad = func(df[gad_cols], df[\"DepressionEncoded\"], k=5)\n",
    "    sel_phq = func(df[phq_cols], df[\"DepressionEncoded\"], k=5)\n",
    "\n",
    "    selected.extend(sel_pss)\n",
    "    selected.extend(sel_gad)\n",
    "    selected.extend(sel_phq)\n",
    "\n",
    "    print(f\"‚úÖ Selected ({len(selected)}):\", selected)\n",
    "\n",
    "    X_sel = df[selected].copy()\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_sel.fillna(0)),\n",
    "        columns=selected\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled,\n",
    "        df[\"DepressionEncoded\"],\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=df[\"DepressionEncoded\"]\n",
    "    )\n",
    "\n",
    "    out_dir = OUT_BASE / name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_df = X_train.copy()\n",
    "    train_df[\"DepressionEncoded\"] = y_train.values\n",
    "\n",
    "    test_df = X_test.copy()\n",
    "    test_df[\"DepressionEncoded\"] = y_test.values\n",
    "\n",
    "    train_df.to_csv(out_dir / \"train.csv\", index=False)\n",
    "    test_df.to_csv(out_dir / \"test.csv\", index=False)\n",
    "\n",
    "    joblib.dump(scaler, out_dir / \"scaler.pkl\")\n",
    "\n",
    "    print(f\"üíæ Saved: train.csv, test.csv, scaler.pkl ‚Üí {out_dir}\")\n",
    "\n",
    "    summary.append({\n",
    "        \"Method\": name,\n",
    "        \"Selected Features\": selected\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806d4015",
   "metadata": {},
   "source": [
    "## Save the Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(summary).to_csv(SUMMARY_PATH, index=False)\n",
    "print(\"\\n‚úÖ Feature selection complete. Summary saved to:\", SUMMARY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136593f",
   "metadata": {},
   "source": [
    "## Summary of Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_path = BASE_DIR / \"summary\" / \"features\" / \"first_working_features_summary\"\n",
    "\n",
    "if summary_path.exists():\n",
    "    summary_df = pd.read_csv(summary_path)\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "    display(summary_df)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No summary file found. Please run all feature selection steps first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
