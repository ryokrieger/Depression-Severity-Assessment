{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7df389",
   "metadata": {},
   "source": [
    "# Model Training (Machine Learning)\n",
    "\n",
    "We train **6 traditional ML classifiers** on nine feature-selection datasets:\n",
    "\n",
    "1. **Logistic Regression**\n",
    "2. **Gradient Boosting Classifier**\n",
    "3. **K-Nearest Neighbours**\n",
    "4. **Random Forest Classifier**\n",
    "5. **Decision Tree Classifier**\n",
    "6. **Support Vector Machine**\n",
    "\n",
    "Metrics → `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals → Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c1edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "BASE_DIR = Path.cwd().parents[1]\n",
    "FEATURES_BASE = BASE_DIR / \"features\" / \"01 - First Working\"\n",
    "PROC_BASE = BASE_DIR / \"results\" / \"01 - First Working\" / \"Machine Learning\"\n",
    "MODEL_BASE = BASE_DIR / \"models\" / \"01 - First Working\" / \"Machine Learning\"\n",
    "FIG_BASE = BASE_DIR / \"figures\" / \"01 - First Working\" / \"Machine Learning\"\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba050ef",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8264",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"SVM\": SVC(probability=True, random_state=RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af3e1",
   "metadata": {},
   "source": [
    "## Train All Six Models Across Nine Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0ac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Training ML models for: RFE\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for RFE to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\01 - First Working\\Machine Learning\\rfe\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: SKB\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for SKB to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\01 - First Working\\Machine Learning\\skb\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: FSCS\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for FSCS to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\01 - First Working\\Machine Learning\\fscs\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: ETC\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for ETC to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\01 - First Working\\Machine Learning\\etc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: PC\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for PC to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\01 - First Working\\Machine Learning\\pc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MI\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MI to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\01 - First Working\\Machine Learning\\mi\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MIR\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MIR to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\01 - First Working\\Machine Learning\\mir\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MU\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MU to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\01 - First Working\\Machine Learning\\mu\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: VT\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for VT to d:\\Programming\\Projects\\Depression Severity Assessment\\results\\01 - First Working\\Machine Learning\\vt\\results_traditional_ml.csv\n"
     ]
    }
   ],
   "source": [
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ Training ML models for: {method.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    train_path = in_dir / \"train.csv\"\n",
    "    test_path = in_dir / \"test.csv\"\n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        print(f\"⚠️ Missing train/test for {method}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    train_df = train_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = test_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "    results = []\n",
    "    proc_out = PROC_BASE / method\n",
    "    model_out = MODEL_BASE / method\n",
    "    fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name, model in MODELS.items():\n",
    "        print(f\" - Training {name} ...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics = compute_metrics(y_test, y_pred)\n",
    "        metrics_row = {\"Model\": name, **metrics}\n",
    "        results.append(metrics_row)\n",
    "\n",
    "        cm_path = fig_out / f\"{name.lower().replace(' ', '_')}_confusion.png\"\n",
    "        plot_and_save_confusion(y_test, y_pred, cm_path, f\"{name} Confusion ({method.upper()})\")\n",
    "\n",
    "        model_path = model_out / f\"{name.lower().replace(' ', '_')}.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    res_df.to_csv(proc_out / \"results_traditional_ml.csv\", index=False)\n",
    "    print(f\"✅ Saved results for {method.upper()} to {proc_out / 'results_traditional_ml.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a2308",
   "metadata": {},
   "source": [
    "## Summary of Model Performance Across All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207b3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798754</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798470</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.790873</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789303</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.765628</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.763984</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.764662</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.762783</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>0.700839</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>0.695469</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.653342</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.643765</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.771709</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.768826</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.766183</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.761599</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.764876</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.761422</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.731550</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.727999</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.676543</td>\n",
       "      <td>0.679687</td>\n",
       "      <td>0.676543</td>\n",
       "      <td>0.676698</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.664598</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.659036</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.787616</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.765043</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.763226</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.743118</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.741258</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733640</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.732153</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.706962</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.699541</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>0.613572</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>0.612318</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.769754</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.769848</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.754196</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.747680</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.747034</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.745410</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.745117</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.695004</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.686164</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.676543</td>\n",
       "      <td>0.677755</td>\n",
       "      <td>0.676543</td>\n",
       "      <td>0.676205</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.732438</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.729139</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.728252</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.724362</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.720988</td>\n",
       "      <td>0.727170</td>\n",
       "      <td>0.720988</td>\n",
       "      <td>0.722886</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.707164</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.706175</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.669136</td>\n",
       "      <td>0.673308</td>\n",
       "      <td>0.669136</td>\n",
       "      <td>0.670615</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>0.646249</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>0.638787</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.791502</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789015</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.776476</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.746233</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.743676</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.739811</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.739143</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666621</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.660088</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>0.612026</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>0.610094</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.788627</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.787144</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.777982</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.774717</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.775970</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.771518</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.739327</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.735712</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.720909</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.715515</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.660019</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.791502</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789015</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.776476</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.742329</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.741473</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.726718</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.723477</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666621</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.660088</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.618314</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.613976</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.805098</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.804128</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.798466</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.796489</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.770838</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.769376</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.748092</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.747375</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.678672</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.671184</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.667277</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.663318</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall        F1 Feature Set\n",
       "18  Logistic Regression  0.800000   0.798754  0.800000  0.798470         ETC\n",
       "23                  SVM  0.790123   0.790873  0.790123  0.789303         ETC\n",
       "19    Gradient Boosting  0.762963   0.765628  0.762963  0.763984         ETC\n",
       "21        Random Forest  0.762963   0.764662  0.762963  0.762783         ETC\n",
       "20                  KNN  0.698765   0.700839  0.698765  0.695469         ETC\n",
       "22        Decision Tree  0.641975   0.653342  0.641975  0.643765         ETC\n",
       "12  Logistic Regression  0.767901   0.771709  0.767901  0.768826        FSCS\n",
       "13    Gradient Boosting  0.760494   0.766183  0.760494  0.761599        FSCS\n",
       "17                  SVM  0.760494   0.764876  0.760494  0.761422        FSCS\n",
       "15        Random Forest  0.728395   0.731550  0.728395  0.727999        FSCS\n",
       "16        Decision Tree  0.676543   0.679687  0.676543  0.676698        FSCS\n",
       "14                  KNN  0.661728   0.664598  0.661728  0.659036        FSCS\n",
       "30  Logistic Regression  0.787654   0.787616  0.787654  0.785772          MI\n",
       "35                  SVM  0.762963   0.765043  0.762963  0.763226          MI\n",
       "33        Random Forest  0.740741   0.743118  0.740741  0.741258          MI\n",
       "31    Gradient Boosting  0.733333   0.733640  0.733333  0.732153          MI\n",
       "32                  KNN  0.706173   0.706962  0.706173  0.699541          MI\n",
       "34        Decision Tree  0.612346   0.613572  0.612346  0.612318          MI\n",
       "36  Logistic Regression  0.770370   0.769754  0.770370  0.769848         MIR\n",
       "39        Random Forest  0.755556   0.753900  0.755556  0.754196         MIR\n",
       "37    Gradient Boosting  0.748148   0.747680  0.748148  0.747034         MIR\n",
       "41                  SVM  0.745679   0.745410  0.745679  0.745117         MIR\n",
       "38                  KNN  0.691358   0.695004  0.691358  0.686164         MIR\n",
       "40        Decision Tree  0.676543   0.677755  0.676543  0.676205         MIR\n",
       "42  Logistic Regression  0.728395   0.732438  0.728395  0.729139          MU\n",
       "47                  SVM  0.723457   0.728252  0.723457  0.724362          MU\n",
       "45        Random Forest  0.720988   0.727170  0.720988  0.722886          MU\n",
       "43    Gradient Boosting  0.706173   0.707164  0.706173  0.706175          MU\n",
       "46        Decision Tree  0.669136   0.673308  0.669136  0.670615          MU\n",
       "44                  KNN  0.639506   0.646249  0.639506  0.638787          MU\n",
       "24  Logistic Regression  0.790123   0.791502  0.790123  0.789015          PC\n",
       "29                  SVM  0.775309   0.776476  0.775309  0.775401          PC\n",
       "27        Random Forest  0.743210   0.746233  0.743210  0.743676          PC\n",
       "25    Gradient Boosting  0.740741   0.739811  0.740741  0.739143          PC\n",
       "26                  KNN  0.666667   0.666621  0.666667  0.660088          PC\n",
       "28        Decision Tree  0.612346   0.612026  0.612346  0.610094          PC\n",
       "0   Logistic Regression  0.787654   0.788627  0.787654  0.787144         RFE\n",
       "5                   SVM  0.775309   0.777982  0.775309  0.774717         RFE\n",
       "3         Random Forest  0.770370   0.775970  0.770370  0.771518         RFE\n",
       "1     Gradient Boosting  0.735802   0.739327  0.735802  0.735712         RFE\n",
       "2                   KNN  0.718519   0.720909  0.718519  0.715515         RFE\n",
       "4         Decision Tree  0.661728   0.662903  0.661728  0.660019         RFE\n",
       "6   Logistic Regression  0.790123   0.791502  0.790123  0.789015         SKB\n",
       "11                  SVM  0.775309   0.776476  0.775309  0.775401         SKB\n",
       "7     Gradient Boosting  0.743210   0.742329  0.743210  0.741473         SKB\n",
       "9         Random Forest  0.723457   0.726718  0.723457  0.723477         SKB\n",
       "8                   KNN  0.666667   0.666621  0.666667  0.660088         SKB\n",
       "10        Decision Tree  0.617284   0.618314  0.617284  0.613976         SKB\n",
       "48  Logistic Regression  0.804938   0.805098  0.804938  0.804128          VT\n",
       "53                  SVM  0.797531   0.798466  0.797531  0.796489          VT\n",
       "49    Gradient Boosting  0.770370   0.770838  0.770370  0.769376          VT\n",
       "51        Random Forest  0.748148   0.748092  0.748148  0.747375          VT\n",
       "50                  KNN  0.679012   0.678672  0.679012  0.671184          VT\n",
       "52        Decision Tree  0.661728   0.667277  0.661728  0.663318          VT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined model summary saved → d:\\Programming\\Projects\\Depression Severity Assessment\\summary\\results\\Results Summary (ML)\\first_working_results_summary\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for method in METHODS:\n",
    "    res_path = PROC_BASE / method / \"results_traditional_ml.csv\"\n",
    "    if res_path.exists():\n",
    "        df = pd.read_csv(res_path)\n",
    "        df[\"Feature Set\"] = method.upper()\n",
    "        all_results.append(df)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing results for {method.upper()}\")\n",
    "\n",
    "if all_results:\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    combined_results = combined_results.sort_values([\"Feature Set\", \"Accuracy\"], ascending=[True, False])\n",
    "    \n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    display(combined_results)\n",
    "\n",
    "    summary_out = BASE_DIR / \"summary\" / \"results\" / \"Results Summary (ML)\" / \"first_working_results_summary\"\n",
    "    combined_results.to_csv(summary_out, index=False)\n",
    "    print(f\"✅ Combined model summary saved → {summary_out}\")\n",
    "else:\n",
    "    print(\"⚠️ No model results found. Please run training first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
