{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8af9ba4",
   "metadata": {},
   "source": [
    "# Model Training (Deep Learning)\n",
    "\n",
    "We train two deep learning models (ANN and 1D-CNN) on each of the nine feature-selection datasets.\n",
    "\n",
    "Metrics → `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals → Confusion Matrices and Accuracy vs Epoch plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21041496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "BASE_DIR = Path.cwd().parents[1]\n",
    "FEATURES_BASE = BASE_DIR / \"features\" / \"01 - First Working\"\n",
    "PROC_BASE = BASE_DIR / \"results\" / \"01 - First Working\" / \"Deep Learning\"\n",
    "MODEL_BASE = BASE_DIR / \"models\" / \"01 - First Working\" / \"Deep Learning\"\n",
    "FIG_BASE = BASE_DIR / \"figures\" / \"01 - First Working\" / \"Deep Learning\"\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ed4a4",
   "metadata": {},
   "source": [
    "## Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f45efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ann(input_dim, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn(input_dim, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Reshape((input_dim, 1)),\n",
    "        layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(32, 3, activation='relu', padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5cc38",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e606464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_accuracy_plot(history, path, title):\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.plot(history.history.get('accuracy', []), label='Train Acc')\n",
    "    ax.plot(history.history.get('val_accuracy', []), label='Val Acc')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e405e7",
   "metadata": {},
   "source": [
    "## Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fbff7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(method, model_type, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE):\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    if not in_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing feature-set: {in_dir}\")\n",
    "\n",
    "    train_df = pd.read_csv(in_dir / \"train.csv\").dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = pd.read_csv(in_dir / \"test.csv\").dropna(subset=[\"DepressionEncoded\"])\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"]).values.astype(np.float32)\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int).values\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"]).values.astype(np.float32)\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int).values\n",
    "\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train_oh = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_oh = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    if model_type == \"ANN\":\n",
    "        model = build_ann(input_dim, num_classes)\n",
    "    else:\n",
    "        model = build_cnn(input_dim, num_classes)\n",
    "\n",
    "    es = callbacks.EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True, mode='max', verbose=0)\n",
    "\n",
    "    history = model.fit(X_train, y_train_oh, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[es], verbose=verbose)\n",
    "\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    metrics = compute_metrics(y_test, y_pred)\n",
    "\n",
    "    proc_out = PROC_BASE / method\n",
    "    model_out = MODEL_BASE / method\n",
    "    fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_file = model_out / f\"{model_type.lower()}_model.h5\"\n",
    "    model.save(model_file)\n",
    "\n",
    "    save_confusion(y_test, y_pred, fig_out / f\"{model_type.lower()}_confusion.png\", f\"{model_type} Confusion ({method})\")\n",
    "    save_accuracy_plot(history, fig_out / f\"{model_type.lower()}_accuracy.png\", f\"{model_type} Accuracy vs Epoch ({method})\")\n",
    "\n",
    "    res_file = proc_out / \"results_deep_learning.csv\"\n",
    "    row = pd.DataFrame([{\"Method\": method, \"Model\": model_type, **metrics}])\n",
    "    if res_file.exists():\n",
    "        row.to_csv(res_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        row.to_csv(res_file, index=False)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042f56e",
   "metadata": {},
   "source": [
    "## Run ANN and CNN for All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8b73fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: RFE\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: SKB\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: FSCS\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: ETC\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: PC\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: MI\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: MIR\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: MU\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Deep learning for: VT\n",
      "============================================================\n",
      " - Training ANN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Training CNN ...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Completed DL training. Summary saved to: d:\\Programming\\Projects\\Depression Severity Assessment\\summary\\results\\Results Summary (DL)\\first_working_results_summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfe</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.752200</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.732405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rfe</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.753388</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.745326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skb</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.736862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skb</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.770762</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.766205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fscs</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.724818</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.719812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fscs</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.753504</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.748255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>etc</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.773308</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.769317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>etc</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.791568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pc</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.748544</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.734647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pc</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>0.763771</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>0.758487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mi</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.772280</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.766015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mi</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.762797</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.754762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mir</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.743577</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.740937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mir</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.768963</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.765848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mu</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.735869</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.734386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mu</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.752262</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.739718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vt</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.789816</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.784483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vt</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.803390</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.802599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Method Model  Accuracy  Precision    Recall        F1\n",
       "0     rfe   ANN  0.738272   0.752200  0.738272  0.732405\n",
       "1     rfe   CNN  0.743210   0.753388  0.743210  0.745326\n",
       "2     skb   ANN  0.740741   0.740674  0.740741  0.736862\n",
       "3     skb   CNN  0.765432   0.770762  0.765432  0.766205\n",
       "4    fscs   ANN  0.723457   0.724818  0.723457  0.719812\n",
       "5    fscs   CNN  0.745679   0.753504  0.745679  0.748255\n",
       "6     etc   ANN  0.772840   0.773308  0.772840  0.769317\n",
       "7     etc   CNN  0.792593   0.795812  0.792593  0.791568\n",
       "8      pc   ANN  0.743210   0.748544  0.743210  0.734647\n",
       "9      pc   CNN  0.758025   0.763771  0.758025  0.758487\n",
       "10     mi   ANN  0.770370   0.772280  0.770370  0.766015\n",
       "11     mi   CNN  0.753086   0.762797  0.753086  0.754762\n",
       "12    mir   ANN  0.743210   0.743577  0.743210  0.740937\n",
       "13    mir   CNN  0.765432   0.768963  0.765432  0.765848\n",
       "14     mu   ANN  0.738272   0.735869  0.738272  0.734386\n",
       "15     mu   CNN  0.735802   0.752262  0.735802  0.739718\n",
       "16     vt   ANN  0.787654   0.789816  0.787654  0.784483\n",
       "17     vt   CNN  0.802469   0.803390  0.802469  0.802599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_all = []\n",
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ Deep learning for: {method.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    for model_type in [\"ANN\", \"CNN\"]:\n",
    "        try:\n",
    "            print(f\" - Training {model_type} ...\")\n",
    "            m = train_and_save(method, model_type)\n",
    "            results_all.append({\"Method\": method, \"Model\": model_type, **m})\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error for {method} {model_type}: {e}\")\n",
    "\n",
    "combined = pd.DataFrame(results_all)\n",
    "combined.to_csv(BASE_DIR / \"summary\" / \"results\" / \"Results Summary (DL)\"/ \"first_working_results_summary\", index=False)\n",
    "print(\"\\n✅ Completed DL training. Summary saved to:\", BASE_DIR / \"summary\" / \"results\" / \"Results Summary (DL)\"/ \"first_working_results_summary\")\n",
    "display(combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
